#!/usr/bin/env python3
"""
åŒ»ç–—BERTæ¨¡å‹æ¼”ç¤ºè„šæœ¬
æ–‡ä»¶è·¯å¾„: scripts/medical_bert_demo.py
ä½œè€…: AI Assistant
åŠŸèƒ½: æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨å’Œè¯„ä¼°ä¸åŒçš„åŒ»ç–—BERTæ¨¡å‹
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from src.knowledge.dialogue_memory_manager import DialogueMemoryManager
import json
import time

def demo_medical_bert_models():
    """æ¼”ç¤ºåŒ»ç–—BERTæ¨¡å‹çš„ä½¿ç”¨"""
    
    print("ğŸ¥ åŒ»ç–—BERTæ¨¡å‹æ¼”ç¤º")
    print("=" * 50)
    
    # 1. æŸ¥çœ‹å¯ç”¨æ¨¡å‹
    print("\nğŸ“‹ 1. æŸ¥çœ‹å¯ç”¨çš„åŒ»ç–—æ¨¡å‹")
    manager = DialogueMemoryManager(memory_db_path="demo_medical_bert_db")
    available_models = manager.get_available_medical_models()
    
    print(f"å½“å‰æ¨¡å‹: {available_models['current_model']['name']}")
    print(f"æ¨¡å‹ç±»å‹: {available_models['current_model']['type']}")
    print(f"æ¨è: {available_models['recommendation']}")
    
    # 2. è¯„ä¼°å½“å‰æ¨¡å‹æ€§èƒ½
    print("\nğŸ“Š 2. è¯„ä¼°å½“å‰æ¨¡å‹æ€§èƒ½")
    performance = manager.evaluate_model_performance()
    
    if "error" not in performance:
        print(f"æ¨¡å‹ç»´åº¦: {performance['model_info']['dimension']}")
        print(f"å¹³å‡å‘é‡èŒƒæ•°: {performance['embedding_stats']['mean_norm']:.4f}")
        print(f"è¯­ä¹‰ç›¸ä¼¼åº¦å‡å€¼: {performance['semantic_quality']['avg_similarity']:.4f}")
    else:
        print(f"è¯„ä¼°å¤±è´¥: {performance['error']}")
    
    # 3. æµ‹è¯•åŒ»ç–—æ–‡æœ¬ç†è§£
    print("\nğŸ§  3. æµ‹è¯•åŒ»ç–—æ–‡æœ¬ç†è§£èƒ½åŠ›")
    test_medical_texts = [
        "æ‚£è€…ä¸»è¯‰èƒ¸ç—›3å¤©ï¼Œä¼´æœ‰å‘¼å¸å›°éš¾",
        "å»ºè®®è¿›è¡Œå† çŠ¶åŠ¨è„‰é€ å½±æ£€æŸ¥",
        "è¡€å¸¸è§„æ˜¾ç¤ºç™½ç»†èƒè®¡æ•°å‡é«˜",
        "æœ¯åæ‚£è€…æ¢å¤è‰¯å¥½ï¼Œæ— å¹¶å‘ç—‡",
        "åŒ–ç–—æ–¹æ¡ˆéœ€è¦æ ¹æ®æ‚£è€…è€å—æ€§è°ƒæ•´"
    ]
    
    print("æµ‹è¯•æ–‡æœ¬:")
    for i, text in enumerate(test_medical_texts, 1):
        print(f"  {i}. {text}")
    
    # ç”ŸæˆåµŒå…¥å‘é‡å¹¶åˆ†æ
    embeddings = manager.embedding_model.encode(test_medical_texts)
    print(f"\nç”ŸæˆåµŒå…¥å‘é‡: {embeddings.shape}")
    
    # è®¡ç®—æ–‡æœ¬é—´ç›¸ä¼¼åº¦
    import numpy as np
    similarity_matrix = np.dot(embeddings, embeddings.T)
    
    print("\næ–‡æœ¬ç›¸ä¼¼åº¦çŸ©é˜µ (å‰3x3):")
    for i in range(min(3, len(similarity_matrix))):
        row = " ".join([f"{similarity_matrix[i][j]:.3f}" for j in range(min(3, len(similarity_matrix[i])))])
        print(f"  [{row}]")
    
    # 4. å°è¯•åˆ‡æ¢åˆ°åŒ»ç–—ä¸“ä¸šæ¨¡å‹
    print("\nğŸ”„ 4. å°è¯•åˆ‡æ¢åˆ°åŒ»ç–—ä¸“ä¸šæ¨¡å‹")
    
    medical_models_to_try = [
        "auto",  # è‡ªåŠ¨é€‰æ‹©
        "biobert",  # BioBERT
        "clinical-bert"  # ClinicalBERT
    ]
    
    for model_name in medical_models_to_try:
        print(f"\nå°è¯•åˆ‡æ¢åˆ°: {model_name}")
        
        # åˆ›å»ºæ–°çš„ç®¡ç†å™¨å®ä¾‹æ¥æµ‹è¯•
        try:
            test_manager = DialogueMemoryManager(
                memory_db_path=f"demo_test_{model_name}_db",
                embedding_model_name=model_name
            )
            
            print(f"âœ… æˆåŠŸåŠ è½½: {test_manager.model_name}")
            print(f"   æ¨¡å‹ç±»å‹: {test_manager._get_model_type()}")
            print(f"   åµŒå…¥ç»´åº¦: {test_manager.embedding_dim}")
            
            # å¿«é€Ÿæ€§èƒ½æµ‹è¯•
            start_time = time.time()
            test_embeddings = test_manager.embedding_model.encode(test_medical_texts[:2])
            end_time = time.time()
            
            print(f"   å¤„ç†é€Ÿåº¦: {(end_time - start_time)*1000:.2f}ms (2ä¸ªæ–‡æœ¬)")
            
        except Exception as e:
            print(f"âŒ åŠ è½½å¤±è´¥: {e}")
    
    # 5. åŒ»ç–—æ–‡æœ¬ç›¸ä¼¼æ€§æœç´¢æ¼”ç¤º
    print("\nğŸ” 5. åŒ»ç–—æ–‡æœ¬ç›¸ä¼¼æ€§æœç´¢æ¼”ç¤º")
    
    # æ·»åŠ ä¸€äº›åŒ»ç–—å¯¹è¯è®°å½•
    sample_dialogues = [
        {
            "patient_id": "P001",
            "user_query": "æˆ‘æœ€è¿‘æ€»æ˜¯æ„Ÿåˆ°èƒ¸é—·æ°”çŸ­ï¼Œè¿™æ˜¯ä»€ä¹ˆåŸå› ï¼Ÿ",
            "agent_response": "èƒ¸é—·æ°”çŸ­å¯èƒ½ä¸å¿ƒè¡€ç®¡ç–¾ç—…ã€å‘¼å¸ç³»ç»Ÿç–¾ç—…æˆ–ç„¦è™‘ç­‰å› ç´ æœ‰å…³ï¼Œå»ºè®®è¿›è¡Œå¿ƒç”µå›¾å’Œèƒ¸éƒ¨Xå…‰æ£€æŸ¥ã€‚"
        },
        {
            "patient_id": "P002", 
            "user_query": "åŒ–ç–—åå‡ºç°æ¶å¿ƒå‘•åï¼Œæœ‰ä»€ä¹ˆç¼“è§£æ–¹æ³•ï¼Ÿ",
            "agent_response": "åŒ–ç–—å¼•èµ·çš„æ¶å¿ƒå‘•åæ˜¯å¸¸è§å‰¯ä½œç”¨ï¼Œå¯ä»¥ä½¿ç”¨æ­¢åè¯ç‰©ï¼ŒåŒæ—¶æ³¨æ„é¥®é£Ÿè°ƒç†ï¼Œå°‘é‡å¤šé¤ã€‚"
        },
        {
            "patient_id": "P003",
            "user_query": "è¡€å‹ä¸€ç›´æ§åˆ¶ä¸å¥½ï¼Œéœ€è¦æ¢è¯å—ï¼Ÿ",
            "agent_response": "è¡€å‹æ§åˆ¶ä¸ä½³éœ€è¦è¯„ä¼°å½“å‰ç”¨è¯æ–¹æ¡ˆï¼Œå¯èƒ½éœ€è¦è°ƒæ•´å‰‚é‡æˆ–æ›´æ¢é™å‹è¯ç‰©ï¼Œå»ºè®®å’¨è¯¢å¿ƒå†…ç§‘åŒ»ç”Ÿã€‚"
        }
    ]
    
    # ä¿å­˜å¯¹è¯è®°å½•
    for dialogue in sample_dialogues:
        manager.save_dialogue_turn(
            patient_id=dialogue["patient_id"],
            user_query=dialogue["user_query"],
            agent_response=dialogue["agent_response"]
        )
    
    # æµ‹è¯•ç›¸ä¼¼æ€§æœç´¢
    search_query = "æˆ‘èƒ¸å£ç–¼ç—›ï¼Œå‘¼å¸æœ‰ç‚¹å›°éš¾"
    print(f"\næœç´¢æŸ¥è¯¢: '{search_query}'")
    
    similar_dialogues = manager.search_similar_dialogues(
        query=search_query,
        k=3,
        similarity_threshold=0.3
    )
    
    print(f"æ‰¾åˆ° {len(similar_dialogues)} æ¡ç›¸ä¼¼å¯¹è¯:")
    for i, dialogue in enumerate(similar_dialogues, 1):
        print(f"  {i}. ç›¸ä¼¼åº¦: {dialogue.get('similarity_score', 0):.3f}")
        print(f"     æ‚£è€…æŸ¥è¯¢: {dialogue.get('user_query', '')[:50]}...")
        print(f"     ç³»ç»Ÿå›å¤: {dialogue.get('agent_response', '')[:50]}...")
        print()
    
    # 6. æ¨¡å‹ä½¿ç”¨å»ºè®®
    print("\nğŸ“ˆ 6. æ¨¡å‹ä½¿ç”¨å»ºè®®")
    print("=" * 50)
    
    recommendations = {
        "è‹±æ–‡åŒ»ç–—æ–‡æœ¬": "æ¨èä½¿ç”¨ BioBERT æˆ– ClinicalBERT",
        "ä¸­æ–‡åŒ»ç–—æ–‡æœ¬": "æ¨èä½¿ç”¨ä¸­æ–‡åŒ»ç–—BERTæˆ–å¤šè¯­è¨€æ¨¡å‹", 
        "é€šç”¨åœºæ™¯": "å¯ä»¥ä½¿ç”¨ sentence-transformers é€šç”¨æ¨¡å‹",
        "é«˜ç²¾åº¦éœ€æ±‚": "æ¨èä½¿ç”¨é¢†åŸŸä¸“ä¸šçš„BERTæ¨¡å‹",
        "å¿«é€Ÿå“åº”": "æ¨èä½¿ç”¨è½»é‡çº§æ¨¡å‹å¦‚ MiniLM"
    }
    
    for scenario, recommendation in recommendations.items():
        print(f"â€¢ {scenario}: {recommendation}")
    
    print(f"\nâœ… æ¼”ç¤ºå®Œæˆï¼")
    print(f"ğŸ’¡ æç¤º: å¯ä»¥é€šè¿‡ manager.switch_embedding_model() åŠ¨æ€åˆ‡æ¢æ¨¡å‹")

def compare_model_performance():
    """æ¯”è¾ƒä¸åŒæ¨¡å‹çš„æ€§èƒ½"""
    
    print("\nğŸ† åŒ»ç–—BERTæ¨¡å‹æ€§èƒ½æ¯”è¾ƒ")
    print("=" * 50)
    
    models_to_compare = [
        ("é€šç”¨æ¨¡å‹", "sentence-transformers/all-MiniLM-L6-v2"),
        ("è‡ªåŠ¨é€‰æ‹©", "auto"),
        ("BioBERT", "biobert"),
        ("ClinicalBERT", "clinical-bert")
    ]
    
    test_queries = [
        "æ‚£è€…å‡ºç°æ€¥æ€§å¿ƒè‚Œæ¢—æ­»ç—‡çŠ¶",
        "è‚¿ç˜¤æ ‡å¿—ç‰©æ£€æŸ¥ç»“æœå¼‚å¸¸",
        "æœ¯åæ„ŸæŸ“é£é™©è¯„ä¼°",
        "åŒ–ç–—è¯ç‰©å‰¯ä½œç”¨ç®¡ç†",
        "å½±åƒå­¦æ£€æŸ¥æ˜¾ç¤ºè‚ºéƒ¨é˜´å½±"
    ]
    
    results = []
    
    for model_desc, model_name in models_to_compare:
        print(f"\næµ‹è¯• {model_desc} ({model_name})...")
        
        try:
            manager = DialogueMemoryManager(
                memory_db_path=f"compare_{model_name.replace('/', '_')}_db",
                embedding_model_name=model_name
            )
            
            # æ€§èƒ½è¯„ä¼°
            start_time = time.time()
            performance = manager.evaluate_model_performance(test_queries)
            end_time = time.time()
            
            if "error" not in performance:
                result = {
                    "model_desc": model_desc,
                    "model_name": manager.model_name,
                    "dimension": performance['model_info']['dimension'],
                    "avg_similarity": performance['semantic_quality']['avg_similarity'],
                    "evaluation_time": end_time - start_time,
                    "status": "æˆåŠŸ"
                }
            else:
                result = {
                    "model_desc": model_desc,
                    "model_name": model_name,
                    "status": "å¤±è´¥",
                    "error": performance['error']
                }
            
            results.append(result)
            
        except Exception as e:
            results.append({
                "model_desc": model_desc,
                "model_name": model_name,
                "status": "å¼‚å¸¸",
                "error": str(e)
            })
    
    # æ˜¾ç¤ºæ¯”è¾ƒç»“æœ
    print("\nğŸ“Š æ€§èƒ½æ¯”è¾ƒç»“æœ:")
    print("-" * 80)
    print(f"{'æ¨¡å‹':<15} {'ç»´åº¦':<8} {'è¯­ä¹‰ç›¸ä¼¼åº¦':<12} {'è¯„ä¼°æ—¶é—´':<10} {'çŠ¶æ€':<8}")
    print("-" * 80)
    
    for result in results:
        if result['status'] == 'æˆåŠŸ':
            print(f"{result['model_desc']:<15} {result['dimension']:<8} "
                  f"{result['avg_similarity']:<12.4f} {result['evaluation_time']:<10.3f}s {result['status']:<8}")
        else:
            print(f"{result['model_desc']:<15} {'N/A':<8} {'N/A':<12} {'N/A':<10} {result['status']:<8}")
    
    print("-" * 80)

if __name__ == "__main__":
    print("ğŸš€ å¯åŠ¨åŒ»ç–—BERTæ¨¡å‹æ¼”ç¤º")
    
    try:
        demo_medical_bert_models()
        compare_model_performance()
        
    except KeyboardInterrupt:
        print("\n\nâ¹ï¸  æ¼”ç¤ºè¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\nâŒ æ¼”ç¤ºè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
    
    print("\nğŸ‘‹ æ¼”ç¤ºç»“æŸ")