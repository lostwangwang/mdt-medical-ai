"""
å¤§è¯­è¨€æ¨¡å‹æ¥å£æ¨¡å—
æ–‡ä»¶è·¯å¾„: src/utils/llm_interface.py
ä½œè€…: å§šåˆš
åŠŸèƒ½: æä¾›ç»Ÿä¸€çš„LLMè°ƒç”¨æ¥å£ï¼Œæ”¯æŒå¤šç§æ¨¡å‹å’Œä»»åŠ¡
è¾“å…¥:
- patient_state: æ‚£è€…çŠ¶æ€å¯¹è±¡ï¼ŒåŒ…å«æ‚£è€…åŸºæœ¬ä¿¡æ¯ã€å†å²è®°å½•ç­‰
- role: è§’è‰²ç±»å‹ï¼Œç”¨äºæŒ‡å®šä¸åŒçš„ä»»åŠ¡ï¼ˆå¦‚MDTã€æ‚£è€…ã€åŒ»ç”Ÿç­‰ï¼‰
- treatment_option: æ²»ç–—é€‰é¡¹å¯¹è±¡ï¼ŒåŒ…å«æ²»ç–—æ–¹æ¡ˆçš„è¯¦ç»†ä¿¡æ¯
- knowledge_context: çŸ¥è¯†åº“ä¸Šä¸‹æ–‡ï¼Œç”¨äºæä¾›é¢å¤–çš„èƒŒæ™¯çŸ¥è¯†
è¾“å‡º:
- æ²»ç–—æ¨ç†æ–‡æœ¬ï¼ŒåŒ…å«å¯¹æ‚£è€…çŠ¶æ€çš„åˆ†æå’Œå¯¹æ²»ç–—é€‰é¡¹çš„å»ºè®®

"""

import json
import logging
import os
from dataclasses import dataclass
from datetime import datetime
from typing import Dict, List, Any, Optional, Union

import openai
from dotenv import load_dotenv
from pandas import DataFrame

load_dotenv()

from ..core.data_models import (
    PatientState,
    TreatmentOption,
    RoleType,
    RoleOpinion,
    DialogueRound, QuestionOpinion, RoleRegistry,
)
import experiments.medqa_types as medqa_types

logger = logging.getLogger(__name__)


@dataclass
class LLMConfig:
    """LLMé…ç½®"""

    model_name: str = None
    api_key: Optional[str] = None
    base_url: Optional[str] = None
    temperature: float = 0.0
    max_tokens: int = 1000
    timeout: int = 30

    def __post_init__(self):
        """ååˆå§‹åŒ–ï¼Œè®¾ç½®é»˜è®¤å€¼"""
        if self.model_name is None:
            self.model_name = os.getenv("MODEL_NAME")
        if self.api_key is None:
            self.api_key = os.getenv("QWEN_API_KEY")
        if self.base_url is None:
            self.base_url = os.getenv("BASE_URL")


class LLMInterface:
    """å¤§è¯­è¨€æ¨¡å‹æ¥å£"""

    def __init__(self, config: LLMConfig = None):
        self.config = config or LLMConfig()
        self._setup_client()

    def _setup_client(self):
        """è®¾ç½®LLMå®¢æˆ·ç«¯ï¼Œæ”¯æŒé˜¿é‡Œäº‘ç™¾ç‚¼å’ŒOpenAI"""
        try:
            # åˆå§‹åŒ–å˜é‡ï¼Œé¿å…ä½œç”¨åŸŸé—®é¢˜
            api_key = self.config.api_key
            base_url = self.config.base_url

            # æ£€æŸ¥APIå¯†é’¥æ˜¯å¦æœ‰æ•ˆ
            if (
                    not api_key
                    or api_key.strip() == ""
                    or api_key == "test-api-key-for-testing"
            ):
                logger.info(
                    "No valid API key provided, LLM client will not be initialized. Using template fallback."
                )
                self.client = None
                return

            # æ ¹æ®base_urlåˆ¤æ–­æ˜¯å¦ä¸ºé˜¿é‡Œäº‘ç™¾ç‚¼
            if base_url and "dashscope" in base_url:
                logger.info("Detected Alibaba Cloud DashScope (ç™¾ç‚¼) configuration")
            elif base_url:
                logger.info(f"Using custom base URL: {base_url}")
            else:
                logger.info("Using OpenAI default endpoint")

            # åˆå§‹åŒ–å®¢æˆ·ç«¯ï¼ˆå…¼å®¹OpenAIæ ¼å¼çš„æ¥å£ï¼‰
            self.client = openai.OpenAI(api_key=api_key, base_url=base_url)
            logger.info(
                f"LLM client initialized successfully with model: {self.config.model_name}"
            )

        except Exception as e:
            logger.warning(f"Failed to initialize LLM client: {e}")
            logger.info("Falling back to template-based responses")
            self.client = None

    def generate_update_agent_opinions_reasoning_medqa(
            self,
            question_state: medqa_types.MedicalQuestionState,
            role: Union[RoleType, RoleRegistry],
            current_round: DialogueRound,
            previous_opinion: Union[RoleOpinion, QuestionOpinion],
            question_options: List[medqa_types.QuestionOption],
            mdt_leader_summary: str = None,
            dataset_name: str = None,
    ):
        """ç”Ÿæˆæ›´æ–°è§’è‰²æœ‰å…³åŒ»å­¦é—®é¢˜çš„æ¨ç†"""

        prompt = self._build_update_agent_opinions_reasoning_prompt_medqa(
            question_state, role, current_round, previous_opinion, question_options, mdt_leader_summary, dataset_name
        )
        try:
            if self.client:
                response = self.client.chat.completions.create(
                    model=self.config.model_name,
                    messages=[
                        {
                            "role": "system",
                            "content": f"ä½ æ˜¯åŒ»ç–—å¤šå­¦ç§‘å›¢é˜Ÿï¼ˆMDTï¼‰ä¸­çš„ä¸€ååŒ»å­¦ä¸“å®¶ã€‚"
                                       f"ä½ åœ¨å¯¹è¯ä¸­éœ€è¦æ ¹æ®è°ƒç”¨æ–¹æä¾›çš„ä¿¡æ¯è¿›è¡ŒåŒ»å­¦æ¨ç†çš„â€œè½¯æ›´æ–°â€ï¼ˆsoft updateï¼‰ã€‚"
                                       f"è¯·éµå®ˆè°ƒç”¨æ–¹çš„æ ¼å¼è¦æ±‚ï¼Œä¸è¦äº§ç”Ÿé¢å¤–å†…å®¹ï¼Œä¹Ÿä¸è¦è™šæ„åŒ»å­¦äº‹å®ã€‚"
                        },
                        {"role": "user", "content": prompt},
                    ],
                    temperature=self.config.temperature,
                    max_tokens=self.config.max_tokens,
                )

                logger.debug(f"LLM response debug: {response}")
                return response.choices[0].message.content.strip()
            else:
                # é™çº§åˆ°æ¨¡æ¿åŒ–å›å¤
                return self._generate_template_reasoning(
                    question_state, role, question_options
                )
        except Exception as e:
            logger.error(f"LLM generation failed: {e}")

    def _build_mdt_leader_content_prompt(
            self,
            question_state: medqa_types.MedicalQuestionState,
            question_options: List[medqa_types.QuestionOption],
            dialogue_round: DialogueRound
    ):
        dialogus_messages = dialogue_round.messages
        agents_messages = "\n\n".join([
            msg for msg in dialogus_messages
        ])
        prompt = f"""
        ä½ æ˜¯å¤šå­¦ç§‘åŒ»ç–—å›¢é˜Ÿï¼ˆMDTï¼‰çš„è´Ÿè´£äººï¼ˆLeaderï¼‰ã€‚
        ä½ çš„ä»»åŠ¡æ˜¯å¯¹æœ¬è½®æ‰€æœ‰æ™ºèƒ½ä½“çš„æ¨ç†å†…å®¹è¿›è¡Œé«˜åº¦æŠ½è±¡çš„æ€»ç»“ï¼Œ
        å¹¶ä¸ºä¸‹ä¸€è½®è®¨è®ºæä¾›æ–¹å‘æ€§çš„å¯¹é½ä¿¡å·ã€‚

        è¾“å…¥ä¿¡æ¯ï¼š
        - é¢˜ç›®ï¼š{question_state.question}
        - é€‰é¡¹ï¼š{[f"{option.name}: {question_state.options[option.name]}" for option in question_options]}
        - æ™ºèƒ½ä½“æ¨ç†å†…å®¹ï¼š{agents_messages}

        è¯·è¾“å‡ºä¸¤éƒ¨åˆ†ï¼š

        ==========================
        â‘  æœ¬è½®æ€»ç»“ï¼ˆSummaryï¼‰
        ==========================
        è¯·åªæ€»ç»“â€œæ¨ç†è¶‹åŠ¿â€ï¼ŒåŒ…æ‹¬ï¼š
        - å“ªäº›é€‰é¡¹å¾—åˆ°æ›´å¤šæ”¯æŒ
        - å“ªäº›æ¨ç†æ–¹å‘å­˜åœ¨åˆ†æ­§
        - æ•´ä½“è®¨è®ºæ˜¯å¦åœ¨æ”¶æ•›
        
        è¦æ±‚ï¼š
        - ä¸åˆ†æå…·ä½“åŒ»å­¦å†…å®¹
        - ä¸å¼•ç”¨è¯æ®
        - ä¸åˆ¤æ–­æ­£ç¡®ç­”æ¡ˆ
        - ä¸å¤è¿°æ™ºèƒ½ä½“æ¨ç†ä¸­çš„ç»†èŠ‚
        
        ==========================
        â‘¡ ä¸‹ä¸€è½®æ–¹å‘ï¼ˆNext Roundï¼‰
        ==========================
        è¯·ç»™æ‰€æœ‰æ™ºèƒ½ä½“æä¾›ä¸‹ä¸€è½®çš„è®¨è®ºæ–¹å‘ï¼š
        - å“ªäº›æ¨ç†åˆ†æ­§éœ€è¦é‡ç‚¹èšç„¦
        - å“ªäº›æ¨ç†æ–¹å‘éœ€è¦è¿›ä¸€æ­¥æ¾„æ¸…æˆ–æ·±åŒ–
        - æå‡º 2â€“3 ä¸ªä¸‹ä¸€è½®åº”èšç„¦å›ç­”çš„é—®é¢˜
        
        è¦æ±‚ï¼š
        - åªæä¾›è®¨è®ºæ–¹å‘ï¼Œä¸æä¾›åŒ»å­¦è§‚ç‚¹
        - ä¸èƒ½è¡¨è¾¾å€¾å‘æˆ–æš—ç¤ºæ­£ç¡®ç­”æ¡ˆ
        """

        return prompt

    def _build_final_mdt_leader_summary_prompt(
            self,
            question_state: medqa_types.MedicalQuestionState,
            question_options: List[medqa_types.QuestionOption],
            dialogue_round: DialogueRound,
            opinions_dict: Dict[Union[RoleType, RoleRegistry], Union[RoleOpinion, QuestionOpinion]] = None,
    ):
        agents_messages = "\n\n".join([
            msg for msg in dialogue_round.messages
        ])
        # agents_opinions_str = "\n\n"

        # æ ¼å¼åŒ–å„è§’è‰²çš„èšåˆæ„è§
        # for role, current_opinion in opinions_dict.items():
        #     agents_opinions_str += self.format_opinion_for_prompt(current_opinion, role)
        #     agents_opinions_str += "\n\n"

        prompt = f"""
        ä½ æ˜¯å¤šå­¦ç§‘åŒ»ç–—å›¢é˜Ÿï¼ˆMDTï¼‰çš„è´Ÿè´£äººï¼ˆLeaderï¼‰ã€‚ä½ çš„ä»»åŠ¡æ˜¯æ ¹æ®æ™ºèƒ½ä½“çš„èšåˆæ„è§ï¼Œå¯¹é¢˜ç›®è¿›è¡Œæœ€ç»ˆæ€»ç»“ï¼Œå¹¶ç»™å‡ºç»“è®ºã€‚

        è¾“å…¥ä¿¡æ¯ï¼š
        - é¢˜ç›®ï¼ˆQUESTIONï¼‰ï¼š{question_state.question}
        - é€‰é¡¹ï¼ˆOPTIONSï¼‰ï¼š{[f"{option.name}: {question_state.options[option.name]}" for option in question_options]}
        - æ™ºèƒ½ä½“å‘è¨€å†…å®¹ï¼š{agents_messages}

        ä»»åŠ¡è¦æ±‚ï¼š
        - ç»¼åˆå„æ™ºèƒ½ä½“å‘è¨€å†…å®¹ï¼Œç»™å‡ºæœ€å¯èƒ½çš„æ­£ç¡®é€‰é¡¹æˆ–æœ€ç»ˆç»“è®ºã€‚
        - æä¾›å†³ç­–ä¾æ®ï¼Œè¯´æ˜ä¸ºä½•é€‰æ‹©è¯¥é€‰é¡¹å¹¶æ’é™¤å…¶ä»–é€‰é¡¹ã€‚
        - è¾“å‡º JSONï¼Œæ ¼å¼å¦‚ä¸‹ï¼š
        {{
            "label": "{{æœ€ç»ˆé€‰é¡¹æ ‡ç­¾}}",
            "content": "{{é€‰é¡¹å†…å®¹}}",
            "decision_reasoning": "{{å†³ç­–æ¨ç†ï¼Œ100~150å­—}}"
        }}
        """
        return prompt

    def _build_llm_recruit_agents_medqa_prompt(
            self,
            question_state: medqa_types.MedicalQuestionState,
            question_options: List[medqa_types.QuestionOption],
    ):
        prompt = f"""
        You are the MDT Leader (Multidisciplinary Team Leader) in a medical intelligent reasoning system.

        Your task is to recruit the most relevant **medical expert roles** (not real people) for this question, focusing on **knowledge-based reasoning** rather than clinical practice judgment.

        ã€Input Informationã€‘
        - Question: {question_state.question}
        - Options: {[f"{option.name}: {question_state.options[option.name]}" for option in question_options]}

        ã€Requirementsã€‘
        1. Recruit 3â€“5 **medical expert roles**, not real individuals.
           - Prefer knowledge-oriented roles such as:
             "Pharmacologist", "Biostatistician", "Clinical Trial Specialist", "Toxicologist", 
             "Epidemiologist", "Medical Informatics Specialist"
           - DO NOT generate personal names, fictional doctors, or real-world people.

        2. Each role must represent a distinct medical subfield to ensure heterogeneity.

        3. Assign a weight (0â€“1) to each expert role based on relevance to answering the question:
           - Core: 0.7â€“1.0
           - Secondary: 0.3â€“0.6
           - Weakly related: 0â€“0.3

        4. Output strictly in JSON, no extra explanation.

        ã€Output Formatã€‘
        {{
          "recruited_experts": [
            {{
              "name": "<RoleTypeEnglish>", 
              "value": "<RoleTypeChinese>",
              "description": "<A concise role description (10â€“25 words)>",
              "weight": <0~1>
            }}
          ]
        }}

        ã€Important Instructionsã€‘
        - Only output role types, not personal identities.
        - Do NOT use or fabricate any real or fictional human names.
        - Focus on **knowledge-driven reasoning** rather than clinical intuition.
        - Ensure JSON is strictly valid.
        """
        return prompt

    def llm_recurt_agents_medqa(
            self,
            question_state: medqa_types.MedicalQuestionState,
            question_options: List[medqa_types.QuestionOption]
    ):
        """
        MDT LEADERè´Ÿè´£é€šè¿‡åˆ†æé—®é¢˜çš„éš¾æ˜“ç¨‹åº¦ï¼Œå¹¶ä¸”ä¸ºæ¯ä¸ªé—®é¢˜æ‹›å‹Ÿå¯¹åº”çš„è§’è‰²
        :param question_state: é—®é¢˜ä¿¡æ¯
        :param question_options: é—®é¢˜é€‰é¡¹
        :return: è¿”å›
        """
        prompt = self._build_llm_recruit_agents_medqa_prompt(question_state, question_options)
        response = self.client.chat.completions.create(
            model=self.config.model_name,
            messages=[
                {
                    "role": "system",
                    "content": (
                        "You are the MDT Leader (Multidisciplinary Team Leader) in a medical reasoning system. "
                        "Recruit medical expert roles using knowledge-based, data-driven reasoning."
                        "Only output a strict JSON; do not include explanations or extra text."
                    )
                },
                {
                    "role": "user",
                    "content": prompt,
                }
            ]
        )
        return response.choices[0].message.content.strip()

    def llm_generate_final_mdt_leader_summary(
            self,
            question_state: medqa_types.MedicalQuestionState,
            question_options: List[medqa_types.QuestionOption],
            dialogue_round: DialogueRound,
            opinions_dict: Dict[Union[RoleType, RoleRegistry], Union[RoleOpinion, QuestionOpinion]] = None,
    ):
        """
        mdt_leaderç”Ÿæˆæœ€ç»ˆæ–¹æ¡ˆ
        :param question_state:
        :param question_options:
        :param dialogue_round:
        :param opinions_dict:
        :return:
        """
        prompt = self._build_final_mdt_leader_summary_prompt(
            question_state, question_options, dialogue_round, opinions_dict
        )
        response = self.client.chat.completions.create(
            model=self.config.model_name,
            messages=[
                {
                    "role": "system",
                    "content": f"ä½ æ˜¯å¤šå­¦ç§‘ä¼šè¯Šï¼ˆMDT, Multidisciplinary Teamï¼‰çš„ä¸€åæˆå‘˜, å½“å‰èº«ä»½ä¸ºä¸€ä½ä¸“ä¸šçš„MDT_LEADERï¼Œ"
                               f"ä½ æ˜¯å¤šå­¦ç§‘åŒ»ç–—å›¢é˜Ÿï¼ˆMDTï¼‰çš„è´Ÿè´£äººï¼ˆLeaderï¼‰ã€‚ä½ çš„ä»»åŠ¡æ˜¯æ ¹æ®æ™ºèƒ½ä½“çš„èšåˆæ„è§ï¼Œå¯¹é¢˜ç›®è¿›è¡Œæ€»ç»“ï¼Œå¹¶ç»™å‡ºæœ€ç»ˆæ–¹æ¡ˆ",
                },
                {"role": "user", "content": prompt},
            ],
            temperature=self.config.temperature,
            max_tokens=self.config.max_tokens,
        )
        return response.choices[0].message.content.strip()

    def llm_generate_mdt_leader_content(
            self,
            question_state: medqa_types.MedicalQuestionState,
            question_options: List[medqa_types.QuestionOption],
            dialogue_round: DialogueRound,
    ):
        prompt = self._build_mdt_leader_content_prompt(question_state, question_options, dialogue_round)
        response = self.client.chat.completions.create(
            model=self.config.model_name,
            messages=[
                {
                    "role": "system",
                    "content": (
                        "ä½ æ˜¯å¤šå­¦ç§‘åŒ»ç–—å›¢é˜Ÿï¼ˆMDTï¼‰çš„Leaderã€‚"
                        "è¯·å¯¹æœ¬è½®æ™ºèƒ½ä½“æ¨ç†å†…å®¹æ€»ç»“æ¨ç†è¶‹åŠ¿ï¼ˆæ”¯æŒé€‰é¡¹ã€åˆ†æ­§ã€æ”¶æ•›æƒ…å†µï¼‰ï¼Œ"
                        "å¹¶ç»™å‡ºä¸‹ä¸€è½®è®¨è®ºæ–¹å‘ã€‚"
                    )
                },
                {"role": "user", "content": prompt},
            ],
            temperature=self.config.temperature,
            max_tokens=self.config.max_tokens,
        )
        return response.choices[0].message.content.strip()

    def generate_update_agent_opinions_reasoning(
            self,
            patient_state: PatientState,
            role: RoleType,
            current_round: DialogueRound,
            previous_opinion: RoleOpinion,
            treatment_options: List[TreatmentOption],
    ) -> str:
        """ç”Ÿæˆæ›´æ–°è§’è‰²æ„è§çš„æ¨ç†"""
        prompt = self._build_update_agent_opinions_reasoning_prompt(
            patient_state, role, current_round, previous_opinion, treatment_options
        )
        try:
            if self.client:
                response = self.client.chat.completions.create(
                    model=self.config.model_name,
                    messages=[
                        {
                            "role": "system",
                            "content": f"ä½ æ˜¯å¤šå­¦ç§‘ä¼šè¯Šï¼ˆMDT, Multidisciplinary Teamï¼‰çš„ä¸€åæˆå‘˜,å½“å‰èº«ä»½ä¸ºä¸€ä½ä¸“ä¸šçš„{role.value}ï¼Œè¯·åŸºäºæ‚£è€…ä¿¡æ¯ã€è§’è‰²ä¸“ä¸šæ€§ã€å¯¹è¯ä¸Šä¸‹æ–‡ã€ä¸Šä¸€è½®å¯¹è¯å’Œå½“å‰å¯¹è¯ï¼Œæ›´æ–°è§’è‰²æ„è§ã€æ²»ç–—åå¥½ã€ç½®ä¿¡åº¦",
                        },
                        {"role": "user", "content": prompt},
                    ],
                    temperature=self.config.temperature,
                    max_tokens=self.config.max_tokens,
                )
                logger.debug(f"LLM response debug: {response}")
                return response.choices[0].message.content.strip()
            else:
                # é™çº§åˆ°æ¨¡æ¿åŒ–å›å¤
                return self._generate_template_reasoning(
                    patient_state, role, treatment_options
                )
        except Exception as e:
            logger.error(f"LLM generation failed: {e}")

    def build_consensus_feedback(self, df: DataFrame, W: float, cur_round: int,
                                 focus_question: medqa_types.QuestionOption):
        """
        æ ¹æ®å½“å‰æ„è§ç”Ÿæˆå…±è¯†åé¦ˆæç¤º
        """
        # è®¡ç®—æ¯ä¸ªé€‰é¡¹çš„å¹³å‡åå¥½
        best_treatment = df["mean"].idxmax()
        print(f"best_treatement:{best_treatment}")
        option = medqa_types.QuestionOption(best_treatment)
        feedback = (
            f"å½“å‰ä¸ºç¬¬{cur_round}è½®è®¨è®ºè½®"
            f"å½“å‰å›¢é˜Ÿä¸€è‡´æ€§æŒ‡æ ‡ Kendall's W = {W:.2f}ã€‚\n"
            f"ç›®å‰å›¢é˜Ÿæ•´ä½“å€¾å‘äºé€‰é¡¹: {option.name}: {option.value}(å¹³å‡åå¥½æœ€é«˜)\n"
            f"è¯·ç»“åˆæ­¤è¶‹åŠ¿ï¼Œé‡æ–°è¯„ä¼°ä½ çš„ç«‹åœºã€‚\n"
            f"å¦‚æœä½ çš„æ„è§ä¸å¤šæ•°ä¸ä¸€è‡´ï¼Œè¯·è¯´æ˜åŸå› ï¼›"
            f"å¦‚æœæ²¡æœ‰å¼ºè¯æ®æ”¯æ’‘å·®å¼‚ï¼Œè¯·è€ƒè™‘é€‚åº¦é æ‹¢ä»¥ä¿ƒè¿›å›¢é˜Ÿå…±è¯†ã€‚"
        )
        return feedback

    def _build_update_agent_opinions_reasoning_prompt_medqa(
            self,
            question_state: medqa_types.MedicalQuestionState,
            role: Union[RoleType, RoleRegistry],
            current_round: DialogueRound,
            previous_opinion: Union[RoleOpinion, QuestionOpinion],
            question_options: List[medqa_types.QuestionOption],
            mdt_leader_summary: str,
            dataset_name: str = None,
    ) -> str:
        cur_round = current_round.round_number
        previous_opinion_str = self.format_opinion_for_prompt(previous_opinion, role.value)
        print(f"[DEBUG]current_round:{current_round}")
        if dataset_name in ["medqa", "pubmedqa", "symcat", "ddxplus", "medbullets"]:
            prompt = f"""
            ä½ æ˜¯ä¸€ååŒ»ç–—å¤šå­¦ç§‘å›¢é˜Ÿï¼ˆMDTï¼‰çš„æˆå‘˜ã€‚
            ä½ çš„å½“å‰è§’è‰²æ˜¯ï¼š{role.value}ï¼ˆ{role.description}ï¼‰ã€‚
            
            å½“å‰è½®æ¬¡ï¼š{cur_round}
            
            é¢˜ç›®ï¼š{question_state.question}
            é€‰é¡¹ï¼š{[f"{o.name}: {question_state.options[o.name]}" for o in question_options]}
            
            ä»¥ä¸‹ä¸ºä½ æœ¬è½®å¯ç”¨çš„ä¿¡æ¯ï¼š
            1. ä½ ä¸Šä¸€è½®çš„è§‚ç‚¹æ‘˜è¦ï¼ˆprevious_opinion_summaryï¼‰ï¼š
               {previous_opinion_str}
            
            2. MDT Leader çš„æœ¬è½®æ€»ç»“ï¼ˆleader_summaryï¼‰ï¼š
               {mdt_leader_summary}
            
            æœ¬è½®ä»»åŠ¡ï¼šè¯·åŸºäº leader_summary å¯¹ä½ çš„åŒ»å­¦æ¨ç†è¿›è¡Œâ€œè½¯æ›´æ–°â€ï¼ˆsoft updateï¼‰ã€‚
            
            è¦æ±‚ï¼š
            - è¯·ä»¥ MDT Leader çš„æ€»ç»“ä¸ºä¸»è¦å‚è€ƒï¼ŒåŒæ—¶ç»“åˆä½ ä¸Šä¸€è½®ä»ç„¶æœ‰æ•ˆçš„åŒ»å­¦é€»è¾‘ï¼Œå¯¹æ¨ç†è¿›è¡Œæ›´æ–°ã€‚
            - ä½ å¯ä»¥ä¿ç•™æ­£ç¡®çš„éƒ¨åˆ†ï¼Œä¹Ÿå¯ä»¥ä¿®æ­£æˆ–å¢å¼ºä½ çš„ç«‹åœº
            - ä¸è¦ç”Ÿæˆè¯„åˆ†æˆ–æ¦‚ç‡
            - ä¸è¦å¼•å…¥ä¸å­˜åœ¨çš„åŒ»å­¦äº‹å®
            - è¾“å‡ºåº”ç®€æ´ã€é€»è¾‘æ¸…æ™°
            
            è¯·ä»¥**ä¸¥æ ¼ JSON æ ¼å¼**è¾“å‡ºï¼š
            {{
              "reasoning": "<80â€“150å­—ä¸­æ–‡æ¨ç†ï¼Œæè¿°ä½ æœ¬è½®å¦‚ä½•æ›´æ–°è§‚ç‚¹>"
            }}
            """
        return prompt

    def _build_update_agent_opinions_reasoning_prompt(
            self,
            patient_state: PatientState,
            role: RoleType,
            current_round: DialogueRound,
            previous_opinion: RoleOpinion,
            treatment_options: List[TreatmentOption],
    ) -> str:
        """æ„å»ºæ›´æ–°è§’è‰²æ„è§çš„æ¨ç†æç¤º"""

        role_descriptions = {
            RoleType.ONCOLOGIST: "è‚¿ç˜¤ç§‘åŒ»ç”Ÿï¼Œå…³æ³¨æ²»ç–—æ•ˆæœå’Œç”Ÿå­˜ç‡",
            RoleType.NURSE: "æŠ¤å£«ï¼Œå…³æ³¨æŠ¤ç†å¯è¡Œæ€§å’Œæ‚£è€…èˆ’é€‚åº¦",
            RoleType.PSYCHOLOGIST: "å¿ƒç†åŒ»ç”Ÿï¼Œå…³æ³¨æ‚£è€…å¿ƒç†å¥åº·",
            RoleType.RADIOLOGIST: "æ”¾å°„ç§‘åŒ»ç”Ÿï¼Œå…³æ³¨å½±åƒå­¦è¡¨ç°å’Œæ”¾å°„æ²»ç–—",
            RoleType.PATIENT_ADVOCATE: "æ‚£è€…ä»£è¡¨ï¼Œå…³æ³¨æ‚£è€…æƒç›Šã€è‡ªä¸»é€‰æ‹©å’Œç”Ÿæ´»è´¨é‡",
            RoleType.NUTRITIONIST: "è¥å…»å¸ˆï¼Œå…³æ³¨æ‚£è€…è¥å…»çŠ¶å†µå’Œè¥å…»æ”¯æŒæ²»ç–—",
            RoleType.REHABILITATION_THERAPIST: "åº·å¤æ²»ç–—å¸ˆï¼Œå…³æ³¨æ‚£è€…åŠŸèƒ½æ¢å¤å’Œç”Ÿæ´»è´¨é‡æ”¹å–„",
        }
        dialogue_text = "\n".join(
            [
                f"{msg.role.value}å½“å‰çš„è§‚ç‚¹æ˜¯: {msg.content}"
                for msg in current_round.messages
            ]
        )
        logger.info("dialogue_text: %s", dialogue_text)
        prompt = f"""
ä½ æ˜¯ä¸€ååŒ»ç–—å¤šå­¦ç§‘å›¢é˜Ÿï¼ˆMDT, Multidisciplinary Teamï¼‰çš„æˆå‘˜ï¼Œå½“å‰èº«ä»½ä¸º **{role.value}**ã€‚  
è¯·æ ¹æ®ä»¥ä¸‹æ‚£è€…ä¿¡æ¯å’Œå›¢é˜Ÿå¯¹è¯å†…å®¹ï¼Œå¯¹æ¯ä¸ªæ²»ç–—æ–¹æ¡ˆè¿›è¡Œç»¼åˆè¯„ä¼°å¹¶é‡æ–°æ‰“åˆ†ã€‚

==============================
ã€æ‚£è€…ä¿¡æ¯ã€‘
- æ‚£è€…ID: {patient_state.patient_id}
- è¯Šæ–­: {patient_state.diagnosis}
- åˆ†æœŸ: {patient_state.stage}
- å¹´é¾„: {patient_state.age}
- ç—‡çŠ¶: {', '.join(patient_state.symptoms)}
- åˆå¹¶ç—‡: {', '.join(patient_state.comorbidities)}
- å®éªŒå®¤ç»“æœ: {json.dumps(patient_state.lab_results, ensure_ascii=False, indent=2)}
- ç”Ÿå‘½ä½“å¾: {json.dumps(patient_state.vital_signs, ensure_ascii=False, indent=2)}
- å¿ƒç†çŠ¶æ€: {patient_state.psychological_status}
- ç”Ÿæ´»è´¨é‡è¯„åˆ†: {patient_state.quality_of_life_score}

==============================
ã€è§’è‰²å†å²æ„è§ã€‘
- è§’è‰²èº«ä»½: {role_descriptions.get(role, role.value)}
- ä¸Šè½®æ¨ç†: {previous_opinion.reasoning}
- ä¸Šè½®æ²»ç–—åå¥½: {json.dumps(previous_opinion.treatment_preferences, ensure_ascii=False, indent=2)}
- ä¸Šè½®æ ¸å¿ƒå…³æ³¨ç‚¹: {json.dumps(previous_opinion.concerns, ensure_ascii=False, indent=2)}
- ä¸Šè½®å®Œæ•´æ„è§: {json.dumps(previous_opinion.__dict__, ensure_ascii=False, indent=2)}

==============================
ã€å¤šå­¦ç§‘å›¢é˜Ÿå¯¹è¯è®°å½•ã€‘
{dialogue_text}

==============================
ã€å½“å‰è§’è‰²åå¥½ã€‘
{role.value} å½“å‰çš„æ²»ç–—åå¥½: {json.dumps(previous_opinion.treatment_preferences, ensure_ascii=False, indent=2)}

==============================
ã€æ²»ç–—é€‰é¡¹åˆ—è¡¨ã€‘
{[option.value for option in treatment_options]}

==============================
ã€ä»»åŠ¡è¦æ±‚ã€‘
è¯·ä» **{role.value}** ä¸“ä¸šè§’åº¦å‡ºå‘ï¼Œç»¼åˆåˆ†æï¼š
- æ‚£è€…æ•´ä½“ç—…æƒ…åŠç‰¹å¾ï¼›
- æœ¬è§’è‰²å†å²æ„è§ä¸å…³æ³¨ç‚¹ï¼›
- å…¶ä»–å­¦ç§‘æˆå‘˜æœ€æ–°å‘è¨€ï¼›
- æœ¬è½®è®¨è®ºçš„å…±è¯†ä¸åˆ†æ­§ï¼›

ä¸ºæ¯ä¸ªæ²»ç–—é€‰é¡¹è¿›è¡Œé‡æ–°è¯„ä¼°ã€‚


è¾“å‡ºç»“æœéœ€æ»¡è¶³ **RoleOpinion ç±»** çš„ç»“æ„ï¼š
1. `treatment_preferences`ï¼šå­—å…¸ï¼Œé”®ä¸ºé€‰é¡¹ç´¢å¼•ï¼ˆå¦‚ "A", "B"ï¼‰ï¼Œå€¼ä¸º -1~1 åå¥½åˆ†ï¼›  
2. `reasoning`ï¼šå­—ç¬¦ä¸²ï¼ˆâ‰¤80å­—ï¼‰ï¼Œè¯´æ˜æ€»ä½“æ‰“åˆ†é€»è¾‘ï¼›  
3. `confidence`ï¼šæµ®ç‚¹æ•°ï¼Œ0~1ï¼Œè¡¨ç¤ºå¯¹å½“å‰åˆ¤æ–­çš„ä¿¡å¿ƒï¼›  
4. `concerns`ï¼šåˆ—è¡¨ï¼ŒåŒ…å« 2~3 æ¡ â‰¤20 å­—çš„å…³é”®æ‹…å¿§ã€‚

==============================
ã€è¾“å‡ºè¦æ±‚ã€‘
- ä¸¥æ ¼è¿”å› JSONï¼Œä¸å¾—åŒ…å«è§£é‡Šæˆ–é¢å¤–æ–‡å­—ï¼›  
- æ‰€æœ‰æ²»ç–—é€‰é¡¹å¿…é¡»å®Œæ•´åŒ…å«åœ¨ `treatment_preferences` ä¸­ï¼›  
- é”®åã€å­—æ®µåã€æ•°æ®ç±»å‹å¿…é¡»å®Œå…¨ç¬¦åˆè¦æ±‚ï¼›  
- è¾“å‡ºå¯ç›´æ¥ç”¨äº RoleOpinion å®ä¾‹åŒ–ã€‚

==============================
ã€è¾“å‡ºç¤ºä¾‹ã€‘
{{
    "role": "{role.value}",
    "treatment_preferences": {{"A": 0.8, "B": 0.5, "C": -0.3}},
    "reasoning": "æ‚£è€…ç—…ç¶å¯åˆ‡é™¤ï¼Œæ‰‹æœ¯é¢„åä¼˜äºä¿å®ˆæ²»ç–—",
    "confidence": 0.85,
    "concerns": ["æœ¯åå¹¶å‘ç—‡é£é™©", "æ‚£è€…è€å—æ€§", "æœ¯ååº·å¤å‘¨æœŸ"]
}}
æ³¨æ„ï¼š`treatment_preferences` çš„é”®å¿…é¡»ä½¿ç”¨é€‰é¡¹ç´¢å¼•ï¼ˆå¦‚ "A"ã€"B"ï¼‰ï¼Œä¸è¦ä½¿ç”¨é€‰é¡¹å…¨æ–‡ã€‚
"""

        logger.info("æ›´æ–°ç«‹åœºçš„prompt: %s", prompt)
        return prompt

    def generate_treatment_reasoning_medqa(
            self,
            question_state: medqa_types.MedicalQuestionState,
            role: Union[RoleType, RoleRegistry],
            question_options: List[medqa_types.QuestionOption] = None,
            dataset_name: str = None
    ) -> str:
        """
        ç”Ÿæˆè§’è‰²çš„åˆå§‹æ„è§
        :param question_state: é—®é¢˜æè¿°
        :param role: è§’è‰²ä¿¡æ¯
        :param question_options: é—®é¢˜é€‰é¡¹
        :param dataset_name: æ•°æ®é›†åç§°
        :return: è¿”å›response
        """

        prompt = self._build_treatment_reasoning_prompt_medqa(
            question_state, role, question_options, dataset_name
        )

        try:
            if self.client:
                response = self.client.chat.completions.create(
                    model=self.config.model_name,
                    messages=[
                        {
                            "role": "system",
                            "content": (
                                f"ä½ æ˜¯åŒ»å­¦å¤šå­¦ç§‘å›¢é˜Ÿï¼ˆMDTï¼‰çš„ä¸“ä¸šåŒ»ç”Ÿæ™ºèƒ½ä½“ã€‚ä½ çš„ä»»åŠ¡æ˜¯åœ¨æ”¶åˆ°ç”¨æˆ·æç¤ºåï¼ŒåŸºäºä½ çš„åŒ»å­¦è§’è‰²ï¼Œå¯¹åŒ»å­¦é¢˜ç›®è¿›è¡Œç»“æ„åŒ–æ¨ç†ï¼Œå¹¶ä¸¥æ ¼æŒ‰ç”¨æˆ·è¦æ±‚çš„æ ¼å¼è¾“å‡ºã€‚"
                            ),
                        },
                        {"role": "user", "content": prompt},
                    ],
                    temperature=self.config.temperature,
                    max_tokens=self.config.max_tokens,
                )
                print(response.choices[0].message.content)
                return response.choices[0].message.content.strip()
            else:
                # é™çº§åˆ°æ¨¡æ¿åŒ–å›å¤
                return self._generate_template_reasoning(
                    question_state, role, question_options
                )
        except Exception as e:
            logger.error(f"LLM generation failed: {e}")
            return self._generate_template_reasoning(
                question_state, role, question_options
            )

    def generate_all_treatment_reasoning_meqa(
            self,
            question_state: medqa_types.MedicalQuestionState,
            role: Union[RoleType, RoleRegistry],
            opinion: QuestionOpinion,
            question_options: List[medqa_types.QuestionOption] = None,
            dataset_name: str = None
    ) -> str:
        """
        æ¯ä¸ªæ™ºèƒ½ä½“åŸºäºåˆå§‹æ„è§ç”Ÿæˆå¯¹è¯
        :param question_state:
        :param role:
        :param opinion:
        :param question_options:
        :param dataset_name:
        :return:
        """

        prompt = self._build_all_treatment_reasoning_prompt_meqa(
            question_state,
            role,
            opinion,
            question_options,
            dataset_name
        )

        try:
            if self.client:
                response = self.client.chat.completions.create(
                    model=self.config.model_name,
                    messages=[
                        {
                            "role": "system",
                            "content": f"ä½ æ˜¯å¤šå­¦ç§‘åŒ»ç–—å›¢é˜Ÿï¼ˆMDTï¼‰çš„æˆå‘˜ï¼Œå½“å‰èº«ä»½ä¸º **{role.value}**ã€‚æè¿°: {role.description}, æƒé‡: {role.weight}"
                                       f"ä½ çš„ä»»åŠ¡æ˜¯æ ¹æ®ä½ ä¹‹å‰ç”Ÿæˆçš„åˆå§‹æ„è§ï¼Œä¸ºæ¯ä¸ªé—®é¢˜é€‰é¡¹ç”Ÿæˆ **åˆå§‹é™ˆè¿°**ã€‚"
                                       f"åˆ†ææ¯ä¸ªé€‰é¡¹ï¼Œè§£é‡Šå…¶å¯èƒ½æ­£ç¡®æˆ–ä¸æ­£ç¡®çš„åŸå› ï¼Œå¹¶å‚è€ƒä½ çš„åˆå§‹æ„è§ä¸­çš„è¯„åˆ†ã€æ¨ç†å’Œè¯æ®ã€‚"
                        },
                        {"role": "user", "content": prompt},
                    ],
                    temperature=self.config.temperature,
                    max_tokens=self.config.max_tokens,
                )
                logger.debug(f"[DEBUGINGç¬¬ä¸€è½®å‘è¨€]LLM response debug å½“å‰å…³æ³¨solving: {role.value}: {response}")
                return response.choices[0].message.content.strip()
            else:
                # é™çº§åˆ°æ¨¡æ¿åŒ–å›å¤
                return self._generate_template_reasoning(
                    question_state, role
                )
        except Exception as e:
            logger.error(f"LLM generation failed: {e}")
            return self._generate_template_reasoning(
                question_state, role
            )

    def _build_all_treatment_reasoning_prompt_meqa(
            self,
            question_state: medqa_types.MedicalQuestionState,
            role: Union[RoleType, RoleRegistry],
            opinion: QuestionOpinion,
            question_options: List[medqa_types.QuestionOption] = None,
            dataset_name: str = None
    ) -> str:
        if dataset_name in ["medqa", "pubmedqa", "symcat", "ddxplus", "medbullets"]:
            prompt = f"""
            ä½ æ˜¯ä¸€ä¸ªå¤šå­¦ç§‘åŒ»ç–—å›¢é˜Ÿï¼ˆMDTï¼‰çš„ä¸€åæˆå‘˜ï¼Œå½“å‰èº«ä»½æ˜¯ **{role.value}**ã€‚
            æè¿°: {role.description}, æƒé‡: {role.weight}

            ä½ çš„ä»»åŠ¡æ˜¯åŸºäºä½ ä¹‹å‰ç”Ÿæˆçš„**åˆæ­¥æ„è§ï¼ˆinitial opinionï¼‰**ï¼Œä¸ºæ¯ä¸ªé€‰é¡¹ç”Ÿæˆæ¸…æ™°çš„**åˆæ­¥é™ˆè¿°ï¼ˆinitial statementï¼‰**ã€‚

            è¯·ä¸¥æ ¼éµå®ˆä»¥ä¸‹è¦æ±‚ï¼š

            ==============================
            è¾“å…¥ä¿¡æ¯

            * é—®é¢˜ï¼š{question_state.question}
            * é€‰é¡¹ï¼š{[f"{option.name}: {question_state.options[option.name]}" for option in question_options]}
            * åˆæ­¥æ„è§ï¼ˆä¸å¾—ä¿®æ”¹ï¼‰ï¼š

              * å„é€‰é¡¹è¯„åˆ†ï¼š{opinion.scores}
              * æ¨ç†ï¼š{opinion.reasoning}
              * è¯æ®ï¼š{opinion.evidences}

            ==============================
            ä»»åŠ¡è¦æ±‚

            1. ä½ å¿…é¡»åˆ†æ**æ¯ä¸ªé€‰é¡¹**ï¼Œè¯´æ˜ä¸ºä»€ä¹ˆå¯èƒ½æ­£ç¡®æˆ–ä¸æ­£ç¡®ã€‚
            2. ä½ çš„åˆ†æå¿…é¡»ä¸¥æ ¼åŸºäºåˆæ­¥æ„è§ä¸­çš„è¯„åˆ†ã€æ¨ç†å’Œè¯æ®ï¼Œä¸å¾—å¼•å…¥ä¸åˆæ­¥æ„è§å†²çªçš„æ–°è§‚ç‚¹ã€‚
            3. **ä¸å¾—é‡æ–°è¯„åˆ†ï¼Œä¸å¾—æ”¹å˜å€¾å‘**ã€‚
            4. åœ¨ç»“å°¾å¿…é¡»æ˜ç¡®è¡¨è¾¾ä½ çš„æœ€ç»ˆæ¨èé€‰é¡¹ï¼Œä¾‹å¦‚ï¼š
               â€œå› æ­¤ï¼Œæ ¹æ®æˆ‘çš„åˆ†æï¼Œæˆ‘è®¤ä¸ºæœ€å¯èƒ½æ­£ç¡®çš„é€‰é¡¹æ˜¯ Xã€‚â€
            5. è¾“å‡ºåº”ç®€æ´æµç•…ï¼Œ150â€“200å­—ï¼Œé€‚åˆ MDT è®¨è®ºç¯å¢ƒã€‚
            6. ä¸éœ€è¦ JSONï¼Œä»…è‡ªç„¶è¯­è¨€è¯´æ˜ã€‚

            ==============================
            è¾“å‡ºç¤ºä¾‹

            â€œé€‰é¡¹A â€¦ï¼›é€‰é¡¹B â€¦ï¼›é€‰é¡¹C â€¦ï¼›â€¦â€¦  
            å› æ­¤ï¼Œæˆ‘è®¤ä¸ºæœ€å¯èƒ½æ­£ç¡®çš„æ˜¯ Cã€‚â€

            ==============================
            ç°åœ¨è¯·ç”Ÿæˆä½ çš„åˆæ­¥é™ˆè¿°ï¼š
            """
        return prompt

    def _build_treatment_reasoning_prompt_medqa(
            self,
            question_state: medqa_types.MedicalQuestionState,
            role: Union[RoleType, RoleRegistry],
            question_options: List[medqa_types.QuestionOption] = None,
            dataset_name: str = None
    ) -> str:
        """æ„å»ºMedQAåœºæ™¯ä¸‹çš„æ²»ç–—æ¨ç†æç¤ºè¯"""
        # role_name = role.name
        role_value = role.value
        role_desc = role.description
        # role_weight = role.weight
        options_str = "\n".join([
            f"{opt.name}. {question_state.options[opt.name]}"
            for opt in question_options
        ])
        if dataset_name in ["medqa", "pubmedqa", "symcat", "ddxplus", "medbullets"]:
            prompt = f"""
            ä½ æ˜¯åŒ»å­¦å¤šå­¦ç§‘å›¢é˜Ÿï¼ˆMDTï¼‰ç³»ç»Ÿä¸­çš„ä¸€ååŒ»ç”Ÿï¼š
            - èº«ä»½ï¼š{role_value}
            - è§’è‰²æè¿°ï¼š{role_desc}

            ä»»åŠ¡ï¼šå¯¹ä¸‹åˆ—åŒ»å­¦é¢˜ç›®è¿›è¡Œä¸“ä¸šæ¨ç†ï¼ˆ**ä»…æ¨ç†ï¼Œä¸è¯„åˆ†ã€ä¸åˆ—è¯æ®ã€ä¸é€é¡¹åˆ†æ**ï¼‰ã€‚

            ==============================
            é¢˜ç›®ï¼š
            {question_state.question}

            é€‰é¡¹ï¼š
            {options_str}
            ==============================

            è¯·ç»™å‡ºä¸€æ®µè¿è´¯ã€è‡ªç„¶çš„åŒ»å­¦æ¨ç†ï¼Œè¯´æ˜ä½ æ˜¯å¦‚ä½•å¾—å‡ºç­”æ¡ˆçš„ã€‚
            æ¨ç†æœ«å°¾è¯·æ˜ç¡®å†™å‡ºï¼š
            â€œAnswer = <é€‰é¡¹å­—æ¯>â€

            ä¸¥æ ¼ JSON è¾“å‡ºï¼ˆç¦æ­¢é¢å¤–å†…å®¹ï¼‰ï¼š
            {{
              "reasoning": "<ä½ çš„æ¨ç†ï¼ˆåŒ…å« Answer = Xï¼‰>"
            }}
            """
        return prompt

    def generate_treatment_reasoning(
            self,
            patient_state: PatientState,
            role: RoleType,
            treatment_option: TreatmentOption,
            knowledge_context: Dict[str, Any] = None,
            treatment_options: List[TreatmentOption] = None,
    ) -> str:
        """ç”Ÿæˆæ²»ç–—æ¨ç†"""

        prompt = self._build_treatment_reasoning_prompt(
            patient_state, role, treatment_option, knowledge_context, treatment_options
        )

        try:
            if self.client:
                response = self.client.chat.completions.create(
                    model=self.config.model_name,
                    messages=[
                        {
                            "role": "system",
                            "content": f"ä½ æ˜¯å¤šå­¦ç§‘ä¼šè¯Šï¼ˆMDT, Multidisciplinary Teamï¼‰çš„ä¸€åæˆå‘˜,å½“å‰èº«ä»½æ˜¯ä¸€ä½ä¸“ä¸šçš„{role.value}ï¼Œè¯·åŸºäºæ‚£è€…ä¿¡æ¯å’Œè§’è‰²ä¸“ä¸šæ€§æä¾›æ²»ç–—æ¨ç†,å¹¶å¯¹æ¯ä¸ªæ²»ç–—é€‰é¡¹çš„ç½®ä¿¡åº¦è¿›è¡Œæ‰“åˆ†",
                        },
                        {"role": "user", "content": prompt},
                    ],
                    temperature=self.config.temperature,
                    max_tokens=self.config.max_tokens,
                )
                logger.debug(f"LLM response debug: {response}")
                return response.choices[0].message.content.strip()
            else:
                # é™çº§åˆ°æ¨¡æ¿åŒ–å›å¤
                return self._generate_template_reasoning(
                    patient_state, role, treatment_option
                )
        except Exception as e:
            logger.error(f"1111 LLM generation failed: {e}")
            return self._generate_template_reasoning(
                patient_state, role, treatment_option
            )

    def generate_focus_treatment_reasoning(
            self,
            patient_state: PatientState,
            role: RoleType,
            opinion: RoleOpinion,
            treatment_option: TreatmentOption,
            treatment_options: List[TreatmentOption] = None,
    ) -> str:
        """ç”Ÿæˆèšç„¦æ²»ç–—é€‰é¡¹çš„æ¨ç†"""

        prompt = self._build_focus_treatment_reasoning_prompt(
            patient_state,
            role,
            opinion,
            treatment_option,
            knowledge_context,
            treatment_options,
        )

        try:
            if self.client:
                response = self.client.chat.completions.create(
                    model=self.config.model_name,
                    messages=[
                        {
                            "role": "system",
                            "content": f"ä½ æ˜¯å¤šå­¦ç§‘ä¼šè¯Šï¼ˆMDT, Multidisciplinary Teamï¼‰çš„ä¸€åæˆå‘˜ï¼Œä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„{role.value}ï¼Œè¯·åŸºäºæ‚£è€…ä¿¡æ¯å’Œè§’è‰²ä¸“ä¸šæ€§æä¾›æ²»ç–—æ¨ç†,å¹¶å¯¹æ¯ä¸ªæ²»ç–—é€‰é¡¹çš„ç½®ä¿¡åº¦è¿›è¡Œæ‰“åˆ†",
                        },
                        {"role": "user", "content": prompt},
                    ],
                    temperature=self.config.temperature,
                    max_tokens=self.config.max_tokens,
                )
                logger.debug(f"LLM response debug: {response}")
                return response.choices[0].message.content.strip()
            else:
                # é™çº§åˆ°æ¨¡æ¿åŒ–å›å¤
                return self._generate_template_reasoning(
                    patient_state, role, treatment_option
                )
        except Exception as e:
            logger.error(f"LLM generation failed: {e}")
            return self._generate_template_reasoning(
                patient_state, role, treatment_option
            )

    def generate_dialogue_response_medqa(
            self,
            question_state: medqa_types.MedicalQuestionState,
            question_options: List[medqa_types.QuestionOption],
            role: Union[RoleType, RoleRegistry],
            current_opinion: Union[RoleOpinion, QuestionOpinion] = None,
            dialogue_history: List[Dict] = None,
            mdt_leader_summary: str = None,
            dataset_name: str = None
    ) -> str:
        """
        åŸºäºæ–°ç«‹åœºè¿›è¡Œä¸€æ¬¡å¤šè½®å¯¹è¯
        :param question_state:
        :param question_options:
        :param role:
        :param current_opinion:
        :param dialogue_history:
        :param mdt_leader_summary:
        :param dataset_name:
        :return:
        """

        prompt = self._build_dialogue_response_prompt_medqa(
            question_state,
            question_options,
            role,
            current_opinion,
            dialogue_history,
            mdt_leader_summary,
            dataset_name
        )
        try:
            print(f"DEBUG: self.client = {self.client}")
            if self.client:
                print("DEBUG: ä½¿ç”¨LLMå®¢æˆ·ç«¯ç”Ÿæˆå¯¹è¯")
                # ä½¿ç”¨æ›´é«˜çš„temperatureå¢åŠ å¤šæ ·æ€§
                response = self.client.chat.completions.create(
                    model=self.config.model_name,
                    messages=[
                        {
                            "role": "system",
                            "content": (
                                f"ä½ æ˜¯å¤šå­¦ç§‘åŒ»ç–—å›¢é˜Ÿï¼ˆMDTï¼‰çš„ä¸€åæˆå‘˜ï¼Œå½“å‰èº«ä»½ä¸º **{role.value}**ã€‚æè¿°: {role.description}, æƒé‡: {role.weight}"
                                "ä½ çš„ä»»åŠ¡æ˜¯åœ¨åŒ»å­¦çŸ¥è¯†é—®ç­”åœºæ™¯ä¸­ï¼Œä»¥ç®€æ´ã€è‡ªç„¶ã€æœ‰ä¸ªäººç‰¹è‰²çš„æ–¹å¼å‚ä¸æ¨ç†å‹è®¨è®ºï¼Œ"
                                "å¹¶æ ¹æ® MDT_LEADER çš„æ€»ç»“ä¸è®¨è®ºæ–¹å‘ç”Ÿæˆä½ çš„è§‚ç‚¹ã€‚ä½ éœ€è¦æ ¹æ®ä½ çš„åŒ»å­¦ä¸“ä¸šè§†è§’ï¼Œ"
                                "ç»“åˆä¸Šä¸€è½®çš„è§‚ç‚¹å’Œ MDT_LEADER çš„æŒ‡å¯¼æ„è§ï¼Œæä¾›æ¸…æ™°ã€ä¸¥è°¨çš„åŒ»å­¦æ¨ç†ã€‚"
                                "è¯·æ³¨æ„ï¼Œä¸è¦ç»™å‡ºæœ€ç»ˆç­”æ¡ˆï¼Œè€Œæ˜¯å¸®åŠ©å›¢é˜Ÿé€æ­¥å½¢æˆå…±è¯†ã€‚"
                            )
                        },
                        {"role": "user", "content": prompt},
                    ],
                    temperature=self.config.temperature,
                    max_tokens=self.config.max_tokens,
                )

                print("DEBUGæŸ¥çœ‹é”™è¯¯: LLMå“åº”åŸå§‹å†…å®¹:", response)
                logger.info(f"æ–°æ–¹æ¡ˆ_MDT_LEADERç”Ÿæˆresponse:{response}")
                response_text = response.choices[0].message.content.strip()
                logger.info(f"DEBUG: LLMå“åº” response_text: {response_text}")
                return response_text
            else:
                print("DEBUG: æ²¡æœ‰LLMå®¢æˆ·ç«¯ï¼Œä½¿ç”¨æ¨¡æ¿å›é€€")
                # å¦‚æœæ²¡æœ‰LLMï¼Œä½¿ç”¨æ¨¡æ¿åŒ–å›é€€
                try:
                    print("DEBUG: å°è¯•è°ƒç”¨ _generate_template_dialogue_fallback")
                    result = self._generate_template_dialogue_fallback(
                        question_state, role, treatment_option, discussion_context
                    )
                    print(f"DEBUG: æ¨¡æ¿æ–¹æ³•è¿”å›: {result}")
                    return result
                except AttributeError as ae:
                    print(f"ğŸš¨ğŸš¨ğŸš¨ DEBUG: AttributeError caught: {ae}")
                    print(f"ğŸš¨ğŸš¨ğŸš¨ DEBUG: Returning hardcoded fallback")
                    return f"è€ƒè™‘åˆ°æ‚£è€…{patient_state.age}å²ï¼Œè¯Šæ–­ä¸º{patient_state.diagnosis}ï¼ˆ{patient_state.stage}ï¼‰ï¼Œä½œä¸º{role.value}ï¼Œæˆ‘è®¤ä¸º{treatment_option.value}æ˜¯å€¼å¾—è€ƒè™‘çš„æ²»ç–—é€‰æ‹©ã€‚"
                except Exception as e:
                    print(f"ğŸš¨ğŸš¨ğŸš¨ DEBUG: Other exception: {type(e).__name__}: {e}")
                    print(f"ğŸš¨ğŸš¨ğŸš¨ DEBUG: Returning hardcoded fallback")
                    return f"è€ƒè™‘åˆ°æ‚£è€…{patient_state.age}å²ï¼Œè¯Šæ–­ä¸º{patient_state.diagnosis}ï¼ˆ{patient_state.stage}ï¼‰ï¼Œä½œä¸º{role.value}ï¼Œæˆ‘è®¤ä¸º{treatment_option.value}æ˜¯å€¼å¾—è€ƒè™‘çš„æ²»ç–—é€‰æ‹©ã€‚"
                except Exception as ee:
                    print(f"DEBUG: å…¶ä»–å¼‚å¸¸: {ee}")
                    return f"è€ƒè™‘åˆ°æ‚£è€…{patient_state.age}å²ï¼Œè¯Šæ–­ä¸º{patient_state.diagnosis}ï¼ˆ{patient_state.stage}ï¼‰ï¼Œä½œä¸º{role.value}ï¼Œæˆ‘è®¤ä¸º{treatment_option.value}æ˜¯å€¼å¾—è€ƒè™‘çš„æ²»ç–—é€‰æ‹©ã€‚"
        except Exception as e:
            print(f"DEBUG: å¼‚å¸¸å‘ç”Ÿ: {e}")
            logger.error(f"Dialogue response generation failed: {e}")
            return self._generate_template_dialogue_fallback(
                patient_state, role, treatment_option, discussion_context
            )

    def generate_dialogue_response(
            self,
            patient_state: PatientState,
            role: RoleType,
            treatment_option: TreatmentOption,
            discussion_context: str,
            knowledge_context: Dict[str, Any] = None,
            current_stance: RoleOpinion = None,
            dialogue_history: List[Dict] = None,
    ) -> str:
        """ç”Ÿæˆè‡ªç„¶çš„å¤šè½®å¯¹è¯å›åº” - å‡å°‘æ¨¡æ¿åŒ–"""

        prompt = self._build_dialogue_response_prompt(
            patient_state,
            role,
            treatment_option,
            discussion_context,
            knowledge_context,
            current_stance,
            dialogue_history,
        )

        try:
            print(f"DEBUG: self.client = {self.client}")
            if self.client:
                print("DEBUG: ä½¿ç”¨LLMå®¢æˆ·ç«¯ç”Ÿæˆå¯¹è¯")
                # ä½¿ç”¨æ›´é«˜çš„temperatureå¢åŠ å¤šæ ·æ€§
                response = self.client.chat.completions.create(
                    model=self.config.model_name,
                    messages=[
                        {
                            "role": "system",
                            "content": f"ä½ æ˜¯å¤šå­¦ç§‘ä¼šè¯Šï¼ˆMDT, Multidisciplinary Teamï¼‰çš„ä¸€åæˆå‘˜ï¼Œä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„{self._get_role_system_prompt(role)}ï¼Œè¯·å’Œå…¶ä»–æ™ºèƒ½ä½“è¿›è¡Œè®¨è®ºï¼Œå¹¶ä¿æŒä¸€è‡´çš„ç«‹åœºï¼Œå¯èƒ½éœ€è¦è®¨è®ºå¤šè½®ã€‚",
                        },
                        {"role": "user", "content": prompt},
                    ],
                    temperature=min(self.config.temperature + 0.2, 1.0),  # å¢åŠ éšæœºæ€§
                    max_tokens=self.config.max_tokens,
                    presence_penalty=0.3,  # å‡å°‘é‡å¤
                    frequency_penalty=0.3,  # å¢åŠ è¯æ±‡å¤šæ ·æ€§
                )
                logger.info(f"ç”Ÿæˆresponse:{response}")
                response_text = response.choices[0].message.content.strip()
                logger.info(f"DEBUG: LLMå“åº” response_text: {response_text}")
                return response_text
            else:
                print("DEBUG: æ²¡æœ‰LLMå®¢æˆ·ç«¯ï¼Œä½¿ç”¨æ¨¡æ¿å›é€€")
                # å¦‚æœæ²¡æœ‰LLMï¼Œä½¿ç”¨æ¨¡æ¿åŒ–å›é€€
                try:
                    print("DEBUG: å°è¯•è°ƒç”¨ _generate_template_dialogue_fallback")
                    result = self._generate_template_dialogue_fallback(
                        patient_state, role, treatment_option, discussion_context
                    )
                    print(f"DEBUG: æ¨¡æ¿æ–¹æ³•è¿”å›: {result}")
                    return result
                except AttributeError as ae:
                    print(f"ğŸš¨ğŸš¨ğŸš¨ DEBUG: AttributeError caught: {ae}")
                    print(f"ğŸš¨ğŸš¨ğŸš¨ DEBUG: Returning hardcoded fallback")
                    return f"è€ƒè™‘åˆ°æ‚£è€…{patient_state.age}å²ï¼Œè¯Šæ–­ä¸º{patient_state.diagnosis}ï¼ˆ{patient_state.stage}ï¼‰ï¼Œä½œä¸º{role.value}ï¼Œæˆ‘è®¤ä¸º{treatment_option.value}æ˜¯å€¼å¾—è€ƒè™‘çš„æ²»ç–—é€‰æ‹©ã€‚"
                except Exception as e:
                    print(f"ğŸš¨ğŸš¨ğŸš¨ DEBUG: Other exception: {type(e).__name__}: {e}")
                    print(f"ğŸš¨ğŸš¨ğŸš¨ DEBUG: Returning hardcoded fallback")
                    return f"è€ƒè™‘åˆ°æ‚£è€…{patient_state.age}å²ï¼Œè¯Šæ–­ä¸º{patient_state.diagnosis}ï¼ˆ{patient_state.stage}ï¼‰ï¼Œä½œä¸º{role.value}ï¼Œæˆ‘è®¤ä¸º{treatment_option.value}æ˜¯å€¼å¾—è€ƒè™‘çš„æ²»ç–—é€‰æ‹©ã€‚"
                except Exception as ee:
                    print(f"DEBUG: å…¶ä»–å¼‚å¸¸: {ee}")
                    return f"è€ƒè™‘åˆ°æ‚£è€…{patient_state.age}å²ï¼Œè¯Šæ–­ä¸º{patient_state.diagnosis}ï¼ˆ{patient_state.stage}ï¼‰ï¼Œä½œä¸º{role.value}ï¼Œæˆ‘è®¤ä¸º{treatment_option.value}æ˜¯å€¼å¾—è€ƒè™‘çš„æ²»ç–—é€‰æ‹©ã€‚"
        except Exception as e:
            print(f"DEBUG: å¼‚å¸¸å‘ç”Ÿ: {e}")
            logger.error(f"Dialogue response generation failed: {e}")
            return self._generate_template_dialogue_fallback(
                patient_state, role, treatment_option, discussion_context
            )

    def _build_focus_treatment_reasoning_prompt(
            self,
            patient_state: PatientState,
            role: RoleType,
            opinion: RoleOpinion,
            treatment_option: TreatmentOption,
            knowledge_context: Dict[str, Any] = None,
            treatment_options: List[TreatmentOption] = None,
    ) -> str:
        """æ„å»ºèšç„¦æ²»ç–—é€‰é¡¹çš„æ¨ç†æç¤ºè¯"""

        role_descriptions = {
            RoleType.ONCOLOGIST: "è‚¿ç˜¤ç§‘åŒ»ç”Ÿï¼Œå…³æ³¨æ²»ç–—æ•ˆæœå’Œç”Ÿå­˜ç‡",
            RoleType.NURSE: "æŠ¤å£«ï¼Œå…³æ³¨æŠ¤ç†å¯è¡Œæ€§å’Œæ‚£è€…èˆ’é€‚åº¦",
            RoleType.PSYCHOLOGIST: "å¿ƒç†åŒ»ç”Ÿï¼Œå…³æ³¨æ‚£è€…å¿ƒç†å¥åº·",
            RoleType.RADIOLOGIST: "æ”¾å°„ç§‘åŒ»ç”Ÿï¼Œå…³æ³¨å½±åƒå­¦è¡¨ç°å’Œæ”¾å°„æ²»ç–—",
            RoleType.PATIENT_ADVOCATE: "æ‚£è€…ä»£è¡¨ï¼Œå…³æ³¨æ‚£è€…æƒç›Šã€è‡ªä¸»é€‰æ‹©å’Œç”Ÿæ´»è´¨é‡",
            RoleType.NUTRITIONIST: "è¥å…»å¸ˆï¼Œå…³æ³¨æ‚£è€…è¥å…»çŠ¶å†µå’Œè¥å…»æ”¯æŒæ²»ç–—",
            RoleType.REHABILITATION_THERAPIST: "åº·å¤æ²»ç–—å¸ˆï¼Œå…³æ³¨æ‚£è€…åŠŸèƒ½æ¢å¤å’Œç”Ÿæ´»è´¨é‡æ”¹å–„",
        }

        prompt = f"""
ä½ æ˜¯ä¸€ååŒ»ç–—å¤šå­¦ç§‘å›¢é˜Ÿï¼ˆMDT, Multidisciplinary Teamï¼‰çš„æˆå‘˜ï¼Œè´Ÿè´£ä»{role.value}ä¸“ä¸šè§’åº¦ç»™å‡ºæœ¬è½®ç»¼åˆæ²»ç–—å»ºè®®ã€‚  
è¯·æ ¹æ®ä»¥ä¸‹ä¿¡æ¯ï¼Œç»“åˆæœ¬è½®å¯¹è¯å†…å®¹ï¼Œå¯¹æ¯ä¸ªæ²»ç–—æ–¹æ¡ˆè¿›è¡Œé‡æ–°è¯„ä¼°ã€‚
æ‚£è€…ä¿¡æ¯ï¼š
- æ‚£è€…ID: {patient_state.patient_id}
- è¯Šæ–­: {patient_state.diagnosis}
- åˆ†æœŸ: {patient_state.stage}
- å¹´é¾„: {patient_state.age}
- ç—‡çŠ¶: {', '.join(patient_state.symptoms)}
- åˆå¹¶ç—‡: {', '.join(patient_state.comorbidities)}
- å®éªŒå®¤ç»“æœ: {json.dumps(patient_state.lab_results, ensure_ascii=False, indent=2)}
- vital_signs: {json.dumps(patient_state.vital_signs, ensure_ascii=False, indent=2)}
- å¿ƒç†çŠ¶æ€: {patient_state.psychological_status}
- ç”Ÿæ´»è´¨é‡è¯„åˆ†: {patient_state.quality_of_life_score}

è§’è‰²èº«ä»½: {role_descriptions.get(role, role.value)}

æ²»ç–—é€‰é¡¹: {[option.value for option in treatment_options]}

è¯·ä»{role.value}çš„ä¸“ä¸šè§’åº¦ï¼Œä¸ºè¯¥æ‚£è€…çš„{treatment_option.value}æ²»ç–—æä¾›è¯¦ç»†çš„æ¨ç†åˆ†æï¼ŒåŒ…æ‹¬ï¼š
1. æ²»ç–—é€‰é¡¹åå¥½å€¼å¤§äº0çš„å¸®æˆ‘åˆ†ææ”¯æŒåŸå› ï¼Œæ²»ç–—é€‰é¡¹åå¥½å€¼å°äº0çš„å¸®æˆ‘åˆ†æåå¯¹åŸå› 
2. å¯èƒ½çš„é£é™©å’Œæ³¨æ„äº‹é¡¹
3. ä¸æ‚£è€…å…·ä½“æƒ…å†µçš„åŒ¹é…åº¦

è¯·ç”¨ä¸“ä¸šä½†æ˜“æ‡‚çš„è¯­è¨€å›ç­”ï¼Œæ§åˆ¶åœ¨200å­—ä»¥å†…ã€‚
"""

        if knowledge_context:
            prompt += f"\n\nç›¸å…³åŒ»å­¦çŸ¥è¯†ï¼š\n{json.dumps(knowledge_context, ensure_ascii=False, indent=2)}"

        return prompt

    def _build_treatment_reasoning_prompt(
            self,
            patient_state: PatientState,
            role: RoleType,
            treatment_option: TreatmentOption,
            knowledge_context: Dict[str, Any] = None,
            treatment_options: List[TreatmentOption] = None,
    ) -> str:
        """æ„å»ºæ²»ç–—æ¨ç†æç¤ºè¯"""

        role_descriptions = {
            RoleType.ONCOLOGIST: "è‚¿ç˜¤ç§‘åŒ»ç”Ÿï¼Œå…³æ³¨æ²»ç–—æ•ˆæœå’Œç”Ÿå­˜ç‡",
            RoleType.NURSE: "æŠ¤å£«ï¼Œå…³æ³¨æŠ¤ç†å¯è¡Œæ€§å’Œæ‚£è€…èˆ’é€‚åº¦",
            RoleType.PSYCHOLOGIST: "å¿ƒç†åŒ»ç”Ÿï¼Œå…³æ³¨æ‚£è€…å¿ƒç†å¥åº·",
            RoleType.RADIOLOGIST: "æ”¾å°„ç§‘åŒ»ç”Ÿï¼Œå…³æ³¨å½±åƒå­¦è¡¨ç°å’Œæ”¾å°„æ²»ç–—",
            RoleType.PATIENT_ADVOCATE: "æ‚£è€…ä»£è¡¨ï¼Œå…³æ³¨æ‚£è€…æƒç›Šã€è‡ªä¸»é€‰æ‹©å’Œç”Ÿæ´»è´¨é‡",
            RoleType.NUTRITIONIST: "è¥å…»å¸ˆï¼Œå…³æ³¨æ‚£è€…è¥å…»çŠ¶å†µå’Œè¥å…»æ”¯æŒæ²»ç–—",
            RoleType.REHABILITATION_THERAPIST: "åº·å¤æ²»ç–—å¸ˆï¼Œå…³æ³¨æ‚£è€…åŠŸèƒ½æ¢å¤å’Œç”Ÿæ´»è´¨é‡æ”¹å–„",
        }

        prompt = f"""
ä½ æ˜¯ä¸€ååŒ»ç–—å¤šå­¦ç§‘å›¢é˜Ÿï¼ˆMDT, Multidisciplinary Teamï¼‰çš„æˆå‘˜ï¼Œè´Ÿè´£ä» {role.value} ä¸“ä¸šè§’åº¦ç»™å‡ºæä¾›æ²»ç–—æ¨ç†ã€‚  

==============================
ã€æ‚£è€…åŸºæœ¬ä¿¡æ¯ã€‘
- æ‚£è€…ID: {patient_state.patient_id}
- ä¸»è¦è¯Šæ–­: {patient_state.diagnosis}
- åˆ†æœŸ: {patient_state.stage}
- å¹´é¾„: {patient_state.age}
- ä¸»è¦ç—‡çŠ¶: {', '.join(patient_state.symptoms)}
- åˆå¹¶ç—‡: {', '.join(patient_state.comorbidities)}
- å®éªŒå®¤ç»“æœ: {json.dumps(patient_state.lab_results, ensure_ascii=False, indent=2)}
- ç”Ÿå‘½ä½“å¾: {json.dumps(patient_state.vital_signs, ensure_ascii=False, indent=2)}
- å¿ƒç†çŠ¶æ€: {patient_state.psychological_status}
- ç”Ÿæ´»è´¨é‡è¯„åˆ†: {patient_state.quality_of_life_score}

==============================
ã€è§’è‰²ä¿¡æ¯ã€‘
- å½“å‰è§’è‰²: {role.value}
- è§’è‰²å®šä¹‰: {role_descriptions.get(role, role.value)}

==============================
ã€æ²»ç–—é€‰é¡¹åˆ—è¡¨ã€‘
{[option.value for option in treatment_options]}


è¾“å‡ºéœ€æ»¡è¶³ä»¥ä¸‹æ ¼å¼ï¼š

==============================
ã€è¾“å‡ºè¦æ±‚ã€‘
- è¾“å‡ºä¸ºä¸¥æ ¼ JSONï¼ˆä¸è¦åŒ…å«è§£é‡Šæˆ–é¢å¤–æ–‡å­—ï¼‰ï¼›
- å­—æ®µè¯´æ˜å¦‚ä¸‹ï¼š
  1. `treatment_preferences`: å­—å…¸ï¼Œé”®ä¸ºæ²»ç–—é€‰é¡¹ç´¢å¼•ï¼ˆå¦‚ "A"ã€"B"ï¼‰ï¼Œå€¼ä¸ºåå¥½åˆ†ï¼ˆ-1~1 æµ®ç‚¹æ•°ï¼‰ï¼›
  2. `reasoning`: å­—ç¬¦ä¸²ï¼Œâ‰¤80å­—ï¼Œè¯´æ˜æ€»ä½“æ‰“åˆ†é€»è¾‘ï¼›
  3. `confidence`: æµ®ç‚¹æ•°ï¼Œ0~1ï¼Œä»£è¡¨æœ¬è§’è‰²å¯¹å½“å‰åˆ¤æ–­çš„ä¿¡å¿ƒï¼›
  4. `concerns`: åˆ—è¡¨ï¼ŒåŒ…å« 2~3 æ¡ â‰¤20 å­—çš„å…³é”®æ‹…å¿§ã€‚

==============================
ã€è¾“å‡ºç¤ºä¾‹ã€‘
{{
    "treatment_preferences": {{"A": 0.8, "B": 0.4, "C": -0.3}},
    "reasoning": "æ‚£è€…ç—…ç¶å¯åˆ‡é™¤ï¼Œæ‰‹æœ¯é¢„åä¼˜äºä¿å®ˆæ²»ç–—",
    "confidence": 0.85,
    "concerns": ["æœ¯åå¹¶å‘ç—‡é£é™©", "æ‚£è€…è€å—æ€§", "æœ¯ååº·å¤å‘¨æœŸ"]
}}
"""

        if knowledge_context:
            prompt += f"\n\nç›¸å…³åŒ»å­¦çŸ¥è¯†ï¼š\n{json.dumps(knowledge_context, ensure_ascii=False, indent=2)}"

        return prompt

    def _generate_template_reasoning(
            self,
            patient_state: PatientState,
            role: RoleType,
            treatment_option: TreatmentOption,
    ) -> str:
        """ç”Ÿæˆæ¨¡æ¿åŒ–æ¨ç†ï¼ˆé™çº§æ–¹æ¡ˆï¼‰"""

        # åŸºç¡€æ‚£è€…ä¿¡æ¯
        age_factor = "å¹´é¾„è¾ƒå¤§" if patient_state.age > 65 else "å¹´é¾„é€‚ä¸­"
        stage_severity = (
            "æ—©æœŸ"
            if "I" in patient_state.stage
            else (
                "ä¸­æ™šæœŸ"
                if "II" in patient_state.stage or "III" in patient_state.stage
                else "æ™šæœŸ"
            )
        )

        templates = {
            RoleType.ONCOLOGIST: {
                TreatmentOption.SURGERY: f"""
åŸºäºæ‚£è€…{patient_state.diagnosis}ï¼ˆ{patient_state.stage}æœŸï¼‰çš„ä¸´åºŠç‰¹å¾åˆ†æï¼š
1. è‚¿ç˜¤åˆ†æœŸè¯„ä¼°ï¼š{stage_severity}è‚¿ç˜¤ï¼Œæ‰‹æœ¯åˆ‡é™¤å¯è·å¾—è‰¯å¥½çš„å±€éƒ¨æ§åˆ¶æ•ˆæœ
2. æ‚£è€…å¹´é¾„å› ç´ ï¼š{age_factor}ï¼ˆ{patient_state.age}å²ï¼‰ï¼Œéœ€è¯„ä¼°æ‰‹æœ¯è€å—æ€§å’Œé¢„æœŸè·ç›Š
3. ç—…ç†å­¦è€ƒè™‘ï¼šæ ¹æ®è‚¿ç˜¤å¤§å°ã€ä½ç½®å’Œä¾µçŠ¯èŒƒå›´ï¼Œæ‰‹æœ¯æ˜¯æ ‡å‡†ä¸€çº¿æ²»ç–—é€‰æ‹©
4. é¢„åè¯„ä¼°ï¼šå®Œæ•´åˆ‡é™¤å¯æ˜¾è‘—æ”¹å–„é•¿æœŸç”Ÿå­˜ç‡ï¼Œå»ºè®®ç§¯ææ‰‹æœ¯æ²»ç–—
5. é£é™©æ•ˆç›Šæ¯”ï¼šæ‰‹æœ¯è·ç›Šæ˜æ˜¾å¤§äºé£é™©ï¼Œç¬¦åˆå¾ªè¯åŒ»å­¦è¯æ®
                """.strip(),
                TreatmentOption.CHEMOTHERAPY: f"""
é’ˆå¯¹{patient_state.diagnosis}ï¼ˆ{patient_state.stage}æœŸï¼‰çš„åŒ–ç–—é€‚åº”ç—‡åˆ†æï¼š
1. åˆ†æœŸç‰¹ç‚¹ï¼šç”±äº{stage_severity}ç–¾ç—…çš„ç‰¹å¾ï¼ŒåŒ–ç–—å¯æœ‰æ•ˆæ§åˆ¶å…¨èº«å¾®è½¬ç§»ç—…ç¶
2. å¹´é¾„è€ƒé‡ï¼šè€ƒè™‘åˆ°{age_factor}æ‚£è€…çš„ç”Ÿç†ç‰¹ç‚¹ï¼Œéœ€é€‰æ‹©åˆé€‚çš„åŒ–ç–—æ–¹æ¡ˆå’Œå‰‚é‡è°ƒæ•´
3. æ²»ç–—ç›®æ ‡ï¼šå› ä¸ºç³»ç»Ÿæ€§æ²»ç–—çš„ä¼˜åŠ¿ï¼Œå¯æ˜¾è‘—é™ä½å¤å‘é£é™©ï¼Œæé«˜æ— ç—…ç”Ÿå­˜æœŸ
4. æ–¹æ¡ˆé€‰æ‹©ï¼šåŸºäºæ‚£è€…è€å—æ€§è¯„ä¼°ï¼Œå»ºè®®é‡‡ç”¨æ ‡å‡†åŒ–ç–—æ–¹æ¡ˆå¹¶ä¸ªä½“åŒ–è°ƒæ•´
5. ç–—æ•ˆé¢„æœŸï¼šç”±äºä¸´åºŠç ”ç©¶æ•°æ®æ”¯æŒï¼ŒåŒ–ç–—å¯æ˜¾è‘—æ”¹å–„æ‚£è€…é¢„åå’Œç”Ÿæ´»è´¨é‡
                """.strip(),
                TreatmentOption.RADIOTHERAPY: f"""
æ”¾å°„æ²»ç–—åœ¨{patient_state.diagnosis}ï¼ˆ{patient_state.stage}æœŸï¼‰ä¸­çš„åº”ç”¨ä»·å€¼ï¼š
1. é€‚åº”ç—‡è¯„ä¼°ï¼š{stage_severity}ç—…å˜ï¼Œæ”¾ç–—å¯æä¾›ç²¾å‡†çš„å±€éƒ¨åŒºåŸŸæ§åˆ¶
2. æŠ€æœ¯é€‰æ‹©ï¼šç°ä»£æ”¾ç–—æŠ€æœ¯å¯æœ€å¤§åŒ–è‚¿ç˜¤å‰‚é‡ï¼Œæœ€å°åŒ–æ­£å¸¸ç»„ç»‡æŸä¼¤
3. è”åˆæ²»ç–—ï¼šä¸æ‰‹æœ¯æˆ–åŒ–ç–—è”åˆå¯è·å¾—ååŒæ•ˆåº”
4. å¹´é¾„å› ç´ ï¼š{age_factor}æ‚£è€…é€šå¸¸èƒ½è¾ƒå¥½è€å—åˆ†æ¬¡æ”¾ç–—
5. é¢„æœŸæ•ˆæœï¼šå¯æ˜¾è‘—é™ä½å±€éƒ¨å¤å‘ç‡ï¼Œæ”¹å–„ç”Ÿæ´»è´¨é‡
                """.strip(),
            },
            RoleType.NURSE: {
                TreatmentOption.SURGERY: f"""
æ‰‹æœ¯æŠ¤ç†è¯„ä¼°å’Œè®¡åˆ’åˆ¶å®šï¼š
1. æœ¯å‰å‡†å¤‡ï¼šæ‚£è€…{age_factor}ï¼Œéœ€åŠ å¼ºæœ¯å‰å®£æ•™å’Œå¿ƒç†æ”¯æŒ
2. é£é™©è¯„ä¼°ï¼šè¯„ä¼°æ‚£è€…æ‰‹æœ¯è€å—æ€§ï¼Œåˆ¶å®šä¸ªæ€§åŒ–æŠ¤ç†è®¡åˆ’
3. æœ¯åç›‘æŠ¤ï¼šå¯†åˆ‡è§‚å¯Ÿç”Ÿå‘½ä½“å¾ï¼Œé¢„é˜²å¹¶å‘ç—‡å‘ç”Ÿ
4. åº·å¤æŒ‡å¯¼ï¼šåˆ¶å®šæ¸è¿›å¼åº·å¤è®¡åˆ’ï¼Œä¿ƒè¿›æ‚£è€…æ—©æœŸæ¢å¤
5. å®¶å±æ•™è‚²ï¼šæŒ‡å¯¼å®¶å±å‚ä¸æŠ¤ç†ï¼Œæä¾›æŒç»­æ”¯æŒ
                """.strip(),
                TreatmentOption.CHEMOTHERAPY: f"""
åŒ–ç–—æŠ¤ç†ç®¡ç†å’Œå®‰å…¨ç›‘æŠ¤ï¼š
1. ç”¨è¯å®‰å…¨ï¼šä¸¥æ ¼æ‰§è¡ŒåŒ–ç–—è¯ç‰©é…ç½®å’Œç»™è¯æµç¨‹
2. å‰¯ä½œç”¨ç›‘æµ‹ï¼šå¯†åˆ‡è§‚å¯Ÿæ¶å¿ƒå‘•åã€éª¨é«“æŠ‘åˆ¶ç­‰ä¸è‰¯ååº”
3. æ„ŸæŸ“é¢„é˜²ï¼š{age_factor}æ‚£è€…å…ç–«
4. è¥å…»æ”¯æŒï¼šè¯„ä¼°è¥å…»çŠ¶å†µï¼Œåˆ¶å®šä¸ªæ€§åŒ–è¥å…»å¹²é¢„æ–¹æ¡ˆ
5. å¿ƒç†æŠ¤ç†ï¼šæä¾›æƒ…æ„Ÿæ”¯æŒï¼Œå¸®åŠ©æ‚£è€…å»ºç«‹æ²»ç–—ä¿¡å¿ƒ
                """.strip(),
                TreatmentOption.RADIOTHERAPY: f"""
æ”¾ç–—æœŸé—´æŠ¤ç†è¦ç‚¹å’Œæ³¨æ„äº‹é¡¹ï¼š
1. çš®è‚¤æŠ¤ç†ï¼šæŒ‡å¯¼æ‚£è€…æ­£ç¡®çš„çš®è‚¤ä¿æŠ¤æ–¹æ³•ï¼Œé¢„é˜²æ”¾å°„æ€§çš®ç‚
2. ä½“ä½å›ºå®šï¼šç¡®ä¿æ¯æ¬¡æ²»ç–—ä½“ä½å‡†ç¡®ï¼Œæé«˜æ”¾ç–—ç²¾åº¦
3. å‰¯ä½œç”¨ç®¡ç†ï¼šç›‘æµ‹å’Œå¤„ç†æ”¾ç–—ç›¸å…³ä¸è‰¯ååº”
4. ç”Ÿæ´»æŒ‡å¯¼ï¼š{age_factor}æ‚£è€…éœ€è¦æ›´å¤šçš„ç”Ÿæ´»æŠ¤ç†æ”¯æŒ
5. éšè®¿æ•™è‚²ï¼šåˆ¶å®šæ”¾ç–—åçš„é•¿æœŸéšè®¿å’Œè‡ªæˆ‘ç®¡ç†è®¡åˆ’
                """.strip(),
            },
            RoleType.PSYCHOLOGIST: {
                TreatmentOption.SURGERY: f"""
æ‰‹æœ¯ç›¸å…³å¿ƒç†å¹²é¢„å’Œæ”¯æŒç­–ç•¥ï¼š
1. æœ¯å‰ç„¦è™‘ï¼š{age_factor}æ‚£è€…å¯¹æ‰‹æœ¯çš„ææƒ§å’Œæ‹…å¿§éœ€è¦ä¸“ä¸šç–å¯¼
2. åº”å¯¹æœºåˆ¶ï¼šè¯„ä¼°æ‚£è€…ç°æœ‰çš„å¿ƒç†åº”å¯¹èµ„æºå’Œæ”¯æŒç³»ç»Ÿ
3. è®¤çŸ¥é‡æ„ï¼šå¸®åŠ©æ‚£è€…å»ºç«‹å¯¹æ‰‹æœ¯æ²»ç–—çš„æ­£ç¡®è®¤çŸ¥
4. å®¶åº­æ”¯æŒï¼šæŒ‡å¯¼å®¶å±å¦‚ä½•æä¾›æœ‰æ•ˆçš„æƒ…æ„Ÿæ”¯æŒ
5. æœ¯åé€‚åº”ï¼šåˆ¶å®šæœ¯åå¿ƒç†åº·å¤è®¡åˆ’ï¼Œä¿ƒè¿›å¿ƒç†å¥åº·æ¢å¤
                """.strip(),
                TreatmentOption.CHEMOTHERAPY: f"""
åŒ–ç–—æœŸé—´å¿ƒç†å¥åº·ç»´æŠ¤å’Œå¹²é¢„ï¼š
1. æƒ…ç»ªç®¡ç†ï¼šå¸®åŠ©æ‚£è€…åº”å¯¹åŒ–ç–—å¸¦æ¥çš„æƒ…ç»ªæ³¢åŠ¨å’ŒæŠ‘éƒå€¾å‘
2. æ²»ç–—ä¾ä»æ€§ï¼šé€šè¿‡å¿ƒç†æ”¯æŒæé«˜æ‚£è€…çš„æ²»ç–—é…åˆåº¦
3. ç”Ÿæ´»è´¨é‡ï¼šå…³æ³¨{age_factor}æ‚£è€…çš„ç”Ÿæ´»è´¨é‡å’Œç¤¾ä¼šåŠŸèƒ½
4. å¸Œæœ›é‡å»ºï¼šå¸®åŠ©æ‚£è€…ç»´æŒç§¯æçš„æ²»ç–—æ€åº¦å’Œç¤¾ä¼šå¸Œæœ›
5. å‹åŠ›ç¼“è§£ï¼šæ•™æˆæœ‰æ•ˆçš„å‹åŠ›ç®¡ç†å’Œæ”¾æ¾æŠ€å·§
                """.strip(),
                TreatmentOption.RADIOTHERAPY: f"""
æ”¾ç–—æœŸé—´å¿ƒç†æ”¯æŒå’Œå¹²é¢„æªæ–½ï¼š
1. æ²»ç–—é€‚åº”ï¼šå¸®åŠ©æ‚£è€…é€‚åº”é•¿æœŸçš„æ”¾ç–—æ²»ç–—è¿‡ç¨‹
2. èº«ä½“å½¢è±¡ï¼šå¤„ç†æ”¾ç–—å¯èƒ½å¸¦æ¥çš„èº«ä½“å½¢è±¡æ”¹å˜é—®é¢˜
3. ç¤¾ä¼šæ”¯æŒï¼š{age_factor}æ‚£è€…æ›´éœ€è¦ç¤¾ä¼šæ”¯æŒç½‘ç»œçš„ç»´æŠ¤
4. ææƒ§ç®¡ç†ï¼šç¼“è§£å¯¹æ”¾å°„æ²»ç–—çš„ææƒ§å’Œè¯¯è§£
5. ç”Ÿæ´»è§„åˆ’ï¼šååŠ©æ‚£è€…åˆ¶å®šæ²»ç–—æœŸé—´çš„ç”Ÿæ´»å®‰æ’å’Œç›®æ ‡
                """.strip(),
            },
        }

        role_templates = templates.get(role, {})
        default_reasoning = f"""
ä½œä¸º{role.value}ï¼Œå¯¹äº{patient_state.diagnosis}ï¼ˆ{patient_state.stage}æœŸï¼‰æ‚£è€…çš„{treatment_option.value}æ²»ç–—å»ºè®®ï¼š
è€ƒè™‘åˆ°æ‚£è€…{age_factor}ï¼ˆ{patient_state.age}å²ï¼‰çš„å…·ä½“æƒ…å†µï¼Œ{treatment_option.value}æ²»ç–—å…·æœ‰é‡è¦çš„ä¸´åºŠä»·å€¼ã€‚
éœ€è¦ç»¼åˆè¯„ä¼°æ‚£è€…çš„æ•´ä½“çŠ¶å†µï¼Œåˆ¶å®šä¸ªæ€§åŒ–çš„æ²»ç–—æ–¹æ¡ˆï¼Œç¡®ä¿æ²»ç–—æ•ˆæœçš„åŒæ—¶æœ€å¤§åŒ–æ‚£è€…çš„ç”Ÿæ´»è´¨é‡ã€‚
å»ºè®®åœ¨å¤šå­¦ç§‘å›¢é˜Ÿåä½œä¸‹ï¼Œä¸ºæ‚£è€…æä¾›æœ€ä¼˜çš„åŒ»ç–—æœåŠ¡ã€‚
        """.strip()

        return role_templates.get(treatment_option, default_reasoning)

    def _generate_template_treatment_plan(
            self, patient_state: PatientState
    ) -> Dict[str, Any]:
        """ç”Ÿæˆæ¨¡æ¿åŒ–æ²»ç–—æ–¹æ¡ˆ"""

        return {
            "primary_treatment": f"é’ˆå¯¹{patient_state.diagnosis}çš„æ ‡å‡†æ²»ç–—æ–¹æ¡ˆ",
            "supportive_care": "ç—‡çŠ¶ç®¡ç†å’Œè¥å…»æ”¯æŒ",
            "timeline": "æ²»ç–—å‘¨æœŸçº¦3-6ä¸ªæœˆ",
            "expected_outcomes": "é¢„æœŸè‰¯å¥½çš„æ²»ç–—ååº”",
            "side_effects": "å¸¸è§å‰¯ä½œç”¨çš„é¢„é˜²å’Œç®¡ç†",
            "follow_up": "å®šæœŸå¤æŸ¥å’Œè¯„ä¼°",
            "generated_by": "template",
            "timestamp": datetime.now().isoformat(),
        }

    def _generate_template_timeline_events(
            self, patient_state: PatientState, days_ahead: int
    ) -> List[Dict[str, Any]]:
        """ç”Ÿæˆæ¨¡æ¿åŒ–æ—¶é—´çº¿äº‹ä»¶"""

        events = []
        for day in range(1, min(days_ahead + 1, 31)):
            if day % 7 == 0:  # æ¯å‘¨æ£€æŸ¥
                events.append(
                    {
                        "day": day,
                        "event_type": "æ£€æŸ¥",
                        "description": "å¸¸è§„è¡€æ¶²æ£€æŸ¥å’Œä½“å¾ç›‘æµ‹",
                        "severity": 2,
                        "requires_intervention": False,
                    }
                )

            if day % 14 == 0:  # åŒå‘¨æ²»ç–—
                events.append(
                    {
                        "day": day,
                        "event_type": "æ²»ç–—",
                        "description": "æŒ‰è®¡åˆ’è¿›è¡Œæ²»ç–—",
                        "severity": 3,
                        "requires_intervention": True,
                    }
                )

        return events

    def _generate_template_dialogue_fallback_NEW(
            self,
            patient_state: PatientState,
            role: RoleType,
            treatment_option: TreatmentOption,
            discussion_context: str,
    ) -> str:
        """ç”Ÿæˆä¸Šä¸‹æ–‡ç›¸å…³çš„æ¨¡æ¿åŒ–å¯¹è¯å›åº”"""
        print("ğŸ”¥ğŸ”¥ğŸ”¥ ENTERING NEW FALLBACK METHOD ğŸ”¥ğŸ”¥ğŸ”¥")
        print(
            f"ğŸ”¥ğŸ”¥ğŸ”¥ Parameters: role={role.value}, treatment={treatment_option.value}, context={discussion_context}"
        )
        result = f"ğŸ”¥ğŸ”¥ğŸ”¥ NEW FALLBACK METHOD CALLED! Role: {role.value}, Treatment: {treatment_option.value}, Context: {discussion_context} ğŸ”¥ğŸ”¥ğŸ”¥"
        print(f"ğŸ”¥ğŸ”¥ğŸ”¥ Returning: {result}")
        return result

    def _generate_template_dialogue_fallback(
            self,
            patient_state: PatientState,
            role: RoleType,
            treatment_option: TreatmentOption,
            discussion_context: str,
    ) -> str:
        """ç”Ÿæˆä¸Šä¸‹æ–‡ç›¸å…³çš„æ¨¡æ¿åŒ–å¯¹è¯å›åº”"""
        return self._generate_template_dialogue_fallback_NEW(
            patient_state, role, treatment_option, discussion_context
        )

    def format_opinion_for_prompt(self, current_opinion: Union[RoleOpinion, QuestionOpinion], role_name: str):
        """
        å°†å•ä¸ªæ™ºèƒ½ä½“çš„ opinion è½¬æ¢ä¸ºé€‚åˆ MDT Prompt è¾“å…¥çš„å®Œæ•´è‡ªç„¶è¯­è¨€ç»“æ„ã€‚

        current_opinion: dict, åŒ…å« keys: scores, reasoning, evidences, evidence_strength
        role_name: str, å½“å‰è§’è‰²å
        è¿”å›: strï¼Œå¯ç›´æ¥æ”¾å…¥ prompt
        """
        # æ ¸å¿ƒè§‚ç‚¹å–å…¨éƒ¨ reasoning
        core_reasoning = current_opinion.reasoning.strip()

        # æœ€ç»ˆå­—ç¬¦ä¸²
        formatted = (
            f"{role_name}è§‚ç‚¹:\n"
            f"æ¨ç†å†…å®¹: {core_reasoning}\n"
        )
        return formatted

    def _build_dialogue_response_prompt_medqa(
            self,
            question_state: medqa_types.MedicalQuestionState,
            question_options: List[medqa_types.QuestionOption],
            role: Union[RoleType, RoleRegistry],
            current_opinion: Union[RoleOpinion, QuestionOpinion],
            dialogue_history: List[Dict[str, str]],
            mdt_leader_summary: str = None,
            dataset_name: str = None
    ):

        # # æ„å»ºç«‹åœºä¿¡æ¯
        stance_info = self.format_opinion_for_prompt(current_opinion, role.value)

        if dataset_name in ["medqa", "pubmedqa", "symcat", "ddxplus", "medbullets"]:
            prompt = f"""
            ä½ æ˜¯å¤šå­¦ç§‘ä¼šè¯Šï¼ˆMDTï¼‰çš„ä¸€åæˆå‘˜ï¼Œå½“å‰èº«ä»½ä¸º **{role.value}**ã€‚æè¿°: {role.description}, æƒé‡: {role.weight} "
            ä½ çš„ä»»åŠ¡æ˜¯åœ¨åŒ»å­¦çŸ¥è¯†é—®ç­”åœºæ™¯ä¸­ï¼Œä»¥ç®€æ´ã€è‡ªç„¶ã€æœ‰ä¸ªäººç‰¹è‰²çš„æ–¹å¼å‚ä¸æ¨ç†å‹è®¨è®ºã€‚
            
            è¯·ä¾æ®ä»¥ä¸‹ä¿¡æ¯ç”Ÿæˆä½ çš„æœ¬è½®è§‚ç‚¹ï¼š
            1. åŒ»ç–—é—®é¢˜ï¼š{question_state.question}
            2. é€‰é¡¹: {[f"{option.name}: {question_state.options[option.name]}" for option in question_options]}
            3. æœ¬è½® MDT_LEADER çš„æ€»ç»“ä¸è®¨è®ºæ–¹å‘ï¼š{mdt_leader_summary}
            4. ä½ ä¸Šä¸€è½®çš„è§‚ç‚¹ï¼ˆè‹¥æœ‰ï¼‰ï¼š{stance_info or "æ— "}
            
            ==============================
            ã€å‘è¨€è¦æ±‚ã€‘
            è¯·ä¸¥æ ¼æ§åˆ¶åœ¨ **2â€“3 å¥** å†…ï¼ŒåŒ…å«ä»¥ä¸‹è¦ç´ ï¼š
            
            â‘  **æ‰¿æ¥ä¸Šä¸€è½®**  
            - è‹¥ä½ ä¸Šä¸€è½®æœ‰è§‚ç‚¹ï¼Œè¯·å…ˆç”¨åŠå¥è¯è¯´æ˜ä½ â€œä¿æŒ/è°ƒæ•´/åæ€â€äº†å“ªäº›çœ‹æ³•  
              ï¼ˆç¤ºä¾‹ï¼šâ€œç›¸æ¯”ä¸Šä¸€è½®ï¼Œæˆ‘ä»è®¤ä¸ºâ€¦ / æˆ‘ä¼šç¨ä½œè°ƒæ•´ï¼Œå› ä¸ºâ€¦â€ï¼‰
            
            â‘¡ **å›åº” MDT_LEADER çš„æ–¹å‘**  
            - æ˜ç¡®å‘¼åº” Leader çš„æ€»ç»“æˆ–æ‰€å¼ºè°ƒçš„é£é™©ç‚¹ã€è¯æ®ç‚¹æˆ–äº‰è®®ç‚¹  
              ï¼ˆç¤ºä¾‹ï¼šâ€œç»“åˆ Leader æŒ‡å‡ºçš„ Xï¼Œæˆ‘è®¤ä¸ºâ€¦â€ï¼‰
            
            â‘¢ **ç»™å‡ºä½ çš„ä¸“ä¸šé£æ ¼è§‚ç‚¹**  
            - åŒ»å­¦æ¨ç†å¿…é¡»æ¸…æ™°ã€ä¸¥è°¨ï¼Œä½†ä¸æ¨¡æ¿åŒ–  
            - æ•´ä½“ç›®æ ‡æ˜¯å¸®åŠ©ç¾¤ä½“é€æ­¥å½¢æˆå…±è¯†
            
            ==============================
            ã€è¾“å‡ºæ ¼å¼ã€‘
            - ä»…è¾“å‡ºè‡ªç„¶è¯­è¨€æ–‡æœ¬ï¼Œä¸è¦ JSONã€ä¸è¦åˆ—ç‚¹å’Œç¼–å·ã€‚  
            - å¥å­è¦é¡ºç•…ã€éæ¨¡æ¿åŒ–ï¼Œèƒ½è¢«è§†ä¸º MDT è®¨è®ºä¸­çš„çœŸå®å¯¹è¯ã€‚
            """
        return prompt

    def _build_dialogue_response_prompt(
            self,
            patient_state: PatientState,
            role: RoleType,
            treatment_option: TreatmentOption,
            discussion_context: str,
            knowledge_context: Dict[str, Any] = None,
            current_stance: RoleOpinion = None,
            dialogue_history: List[Dict] = None,
    ) -> str:
        """æ„å»ºå¯¹è¯å›åº”æç¤ºè¯ - å¼ºè°ƒè‡ªç„¶æ€§å’Œä¸ªæ€§åŒ–"""

        # æ„å»ºå¯¹è¯å†å²ä¸Šä¸‹æ–‡
        history_context = ""
        if dialogue_history:
            recent_exchanges = dialogue_history
            history_context = "\nä¸Šä¸€è½®å¯¹è¯:\n"
            for i, exchange in enumerate(recent_exchanges):
                history_context += f"ä¸Šä¸€è½®{i + 1}: {exchange.get('role', 'Unknown')} - {exchange.get('content', '')}...\n"

        logger.info(f"ä¸Šä¸€è½®éè‡ªå·±çš„å¯¹è¯: {history_context}")

        # æ„å»ºç«‹åœºä¿¡æ¯
        stance_info = ""

        if current_stance:
            stance_value = current_stance.treatment_preferences.get(
                treatment_option.value, 0
            )
            if stance_value > 0.7:
                stance_info = "ä½ å¯¹è¯¥æ²»ç–—æ–¹æ¡ˆæŒç§¯ææ€åº¦"
            elif stance_value > 0:
                stance_info = "ä½ å¯¹è¯¥æ²»ç–—æ–¹æ¡ˆæŒè°¨æ…æ”¯æŒæ€åº¦"
            elif stance_value < -0.5:
                stance_info = "ä½ å¯¹è¯¥æ²»ç–—æ–¹æ¡ˆæœ‰è¾ƒå¤§æ‹…å¿§"
            else:
                stance_info = "ä½ å¯¹è¯¥æ²»ç–—æ–¹æ¡ˆæŒä¸­æ€§æ€åº¦"
        logger.info(f"{role.value}å½“å‰ç«‹åœºStance info: {stance_info}")
        prompt = f"""
ä½ æ˜¯ä¸€ååŒ»ç–—å¤šå­¦ç§‘å›¢é˜Ÿï¼ˆMDT, Multidisciplinary Teamï¼‰çš„æˆå‘˜ï¼Œå½“å‰èº«ä»½ä¸º **{role.value}**ã€‚  
è¯·é’ˆå¯¹ä»¥ä¸‹æ‚£è€…æƒ…å†µå’Œè®¨è®ºå†…å®¹ï¼Œç»™å‡ºè‡ªç„¶ã€ä¸“ä¸šä¸”è§’è‰²ç‰¹è‰²é²œæ˜çš„å›åº”ï¼š

==============================
ã€æ‚£è€…ä¿¡æ¯ã€‘
- æ‚£è€…ID: {patient_state.patient_id}
- è¯Šæ–­: {patient_state.diagnosis}
- åˆ†æœŸ: {patient_state.stage}
- å¹´é¾„: {patient_state.age}
- ç—‡çŠ¶: {', '.join(patient_state.symptoms)}
- åˆå¹¶ç—‡: {', '.join(patient_state.comorbidities)}
- å®éªŒå®¤ç»“æœ: {json.dumps(patient_state.lab_results, ensure_ascii=False, indent=2)}
- ç”Ÿå‘½ä½“å¾: {json.dumps(patient_state.vital_signs, ensure_ascii=False, indent=2)}
- å¿ƒç†çŠ¶æ€: {patient_state.psychological_status}
- ç”Ÿæ´»è´¨é‡è¯„åˆ†: {patient_state.quality_of_life_score}

==============================
ã€è®¨è®ºæ–¹æ¡ˆã€‘
- å½“å‰è®¨è®ºçš„æ²»ç–—æ–¹æ¡ˆ: {treatment_option.value}

==============================
ã€è®¨è®ºèƒŒæ™¯ã€‘
- å½“å‰è®¨è®ºèƒŒæ™¯: {discussion_context}
- å½“å‰ç«‹åœºä¿¡æ¯: {stance_info}
- å†å²è®¨è®ºå†…å®¹: {history_context}

==============================
ã€ä»»åŠ¡è¦æ±‚ã€‘
è¯·ä» **{role.value}** ä¸“ä¸šè§’åº¦å‡ºå‘ç”Ÿæˆå›åº”ï¼š
1. å›åº”è‡ªç„¶æµç•…ï¼Œé¿å…æ¨¡æ¿åŒ–è¡¨è¾¾ï¼›
2. ä½“ç°ä½ çš„ä¸“ä¸šè§’è‰²ç‰¹ç‚¹å’Œåˆ¤æ–­é€»è¾‘ï¼›
3. è€ƒè™‘ä¹‹å‰å¯¹è¯å†…å®¹ï¼Œä¿æŒè¿è´¯æ€§ï¼›
4. è¡¨è¾¾å¸¦æœ‰ä¸ªäººè‰²å½©ï¼Œä¸åƒç¯‡ä¸€å¾‹ï¼›
5. é•¿åº¦æ§åˆ¶åœ¨ 2~3 å¥è¯ï¼Œç®€æ´æœ‰åŠ›ï¼›
6. å¦‚æœ‰ä¸åŒæ„è§ï¼Œç¤¼è²Œä¸”åšå®šåœ°è¡¨è¾¾ã€‚

==============================
ã€è¾“å‡ºè¦æ±‚ã€‘
- ä»…è¿”å›æ–‡å­—å›åº”ï¼Œä¸å¾—åŒ…å« JSON æˆ–é¢å¤–æ ‡è®°ï¼›
- å›åº”åº”å¯ç›´æ¥ç”¨äºå¤šæ™ºèƒ½ä½“ MDT å¯¹è¯ç³»ç»Ÿã€‚
"""

        return prompt

    def _get_role_system_prompt(self, role: RoleType) -> str:
        """è·å–è§’è‰²ç‰¹å®šçš„ç³»ç»Ÿæç¤ºè¯"""

        role_prompts = {
            RoleType.ONCOLOGIST: "ä½ æ˜¯ä¸€ä½ç»éªŒä¸°å¯Œçš„è‚¿ç˜¤ç§‘åŒ»ç”Ÿï¼Œä¸“æ³¨äºç™Œç—‡æ²»ç–—çš„ç–—æ•ˆå’Œå®‰å…¨æ€§ã€‚ä½ çš„å›åº”åº”è¯¥åŸºäºå¾ªè¯åŒ»å­¦ï¼ŒåŒæ—¶è€ƒè™‘æ‚£è€…çš„æ•´ä½“çŠ¶å†µã€‚è¯´è¯é£æ ¼ä¸“ä¸šä½†æ˜“æ‡‚ï¼Œå¶å°”ä¼šå¼•ç”¨ä¸´åºŠç»éªŒã€‚",
            RoleType.NURSE: "ä½ æ˜¯ä¸€ä½èµ„æ·±çš„è‚¿ç˜¤ç§‘æŠ¤å£«ï¼Œå…³æ³¨æ‚£è€…çš„æ—¥å¸¸æŠ¤ç†å’Œç”Ÿæ´»è´¨é‡ã€‚ä½ çš„å›åº”åº”è¯¥å®ç”¨ã€è´´å¿ƒï¼Œå…³æ³¨æ²»ç–—çš„å¯è¡Œæ€§å’Œæ‚£è€…çš„èˆ’é€‚åº¦ã€‚è¯´è¯é£æ ¼æ¸©å’Œå…³æ€€ï¼Œç»å¸¸ä»æŠ¤ç†è§’åº¦æ€è€ƒé—®é¢˜ã€‚",
            RoleType.PSYCHOLOGIST: "ä½ æ˜¯ä¸€ä½ä¸´åºŠå¿ƒç†å­¦å®¶ï¼Œä¸“æ³¨äºç™Œç—‡æ‚£è€…çš„å¿ƒç†å¥åº·ã€‚ä½ çš„å›åº”åº”è¯¥è€ƒè™‘æ‚£è€…çš„å¿ƒç†æ‰¿å—èƒ½åŠ›å’Œæƒ…æ„Ÿéœ€æ±‚ã€‚è¯´è¯é£æ ¼æ¸©æš–æ”¯æŒï¼Œå–„äºä»å¿ƒç†è§’åº¦åˆ†æé—®é¢˜ã€‚",
            RoleType.RADIOLOGIST: "ä½ æ˜¯ä¸€ä½æ”¾å°„ç§‘åŒ»ç”Ÿï¼Œä¸“ç²¾äºåŒ»å­¦å½±åƒå’Œæ”¾å°„æ²»ç–—ã€‚ä½ çš„å›åº”åº”è¯¥åŸºäºå½±åƒå­¦è¯æ®å’Œæ”¾å°„æ²»ç–—çš„æŠ€æœ¯ç‰¹ç‚¹ã€‚è¯´è¯é£æ ¼ç²¾ç¡®å®¢è§‚ï¼Œç»å¸¸å¼•ç”¨å½±åƒå­¦å‘ç°ã€‚",
            RoleType.PATIENT_ADVOCATE: "ä½ æ˜¯ä¸€ä½æ‚£è€…æƒç›Šä»£è¡¨ï¼Œè‡´åŠ›äºç»´æŠ¤æ‚£è€…çš„æœ€ä½³åˆ©ç›Šã€‚ä½ çš„å›åº”åº”è¯¥å¹³è¡¡åŒ»ç–—å»ºè®®å’Œæ‚£è€…çš„ä»·å€¼è§‚ã€åå¥½ã€‚è¯´è¯é£æ ¼åšå®šä½†å¯Œæœ‰åŒç†å¿ƒï¼Œç»å¸¸ç«™åœ¨æ‚£è€…è§’åº¦æ€è€ƒã€‚",
        }

        return role_prompts.get(
            role, f"ä½ æ˜¯ä¸€ä½{role.value}ï¼Œè¯·åŸºäºä½ çš„ä¸“ä¸šèƒŒæ™¯æä¾›å»ºè®®ã€‚"
        )

    def _parse_treatment_plan_response(self, response: str) -> Dict[str, Any]:
        """è§£ææ²»ç–—æ–¹æ¡ˆå“åº”"""
        try:
            # å°è¯•è§£æJSON
            if "```json" in response:
                json_start = response.find("```json") + 7
                json_end = response.find("```", json_start)
                json_str = response[json_start:json_end].strip()
            else:
                json_str = response.strip()

            plan = json.loads(json_str)
            plan["generated_by"] = "llm"
            plan["timestamp"] = datetime.now().isoformat()
            return plan
        except:
            # è§£æå¤±è´¥æ—¶è¿”å›æ–‡æœ¬æ ¼å¼
            return {
                "content": response,
                "generated_by": "llm_text",
                "timestamp": datetime.now().isoformat(),
            }

    def _generate_template_dialogue_fallback(
            self,
            patient_state: PatientState,
            role: RoleType,
            treatment_option: TreatmentOption,
            discussion_context: str,
    ) -> str:
        """ç”Ÿæˆæ¨¡æ¿åŒ–å¯¹è¯å›é€€å“åº”"""

        # åŸºç¡€è§’è‰²æ¨¡æ¿
        role_templates = {
            RoleType.ONCOLOGIST: {
                TreatmentOption.SURGERY: "ä»è‚¿ç˜¤å­¦è§’åº¦åˆ†æï¼Œæ‰‹æœ¯æ²»ç–—å¯¹è¯¥æ‚£è€…å…·æœ‰é‡è¦æ„ä¹‰ã€‚",
                TreatmentOption.CHEMOTHERAPY: "åŒ–ç–—æ–¹æ¡ˆéœ€è¦æ ¹æ®æ‚£è€…çš„å…·ä½“ç—…ç†ç‰¹å¾è¿›è¡Œä¸ªä½“åŒ–è®¾è®¡ã€‚",
                TreatmentOption.RADIOTHERAPY: "æ”¾å°„æ²»ç–—åœ¨è¯¥æ‚£è€…çš„ç»¼åˆæ²»ç–—æ–¹æ¡ˆä¸­å¯å‘æŒ¥å…³é”®ä½œç”¨ã€‚",
                TreatmentOption.IMMUNOTHERAPY: "å…ç–«æ²»ç–—ä¸ºè¯¥æ‚£è€…æä¾›äº†æ–°çš„æ²»ç–—æœºä¼šå’Œå¸Œæœ›ã€‚",
                TreatmentOption.PALLIATIVE_CARE: "å§‘æ¯æ²»ç–—èƒ½å¤Ÿæœ‰æ•ˆæ”¹å–„æ‚£è€…çš„ç”Ÿæ´»è´¨é‡ã€‚",
                TreatmentOption.WATCHFUL_WAITING: "å¯†åˆ‡è§‚å¯Ÿç­–ç•¥åœ¨å½“å‰é˜¶æ®µæ˜¯åˆç†çš„é€‰æ‹©ã€‚",
            },
            RoleType.SURGEON: {
                TreatmentOption.SURGERY: "ä»å¤–ç§‘è§’åº¦è¯„ä¼°ï¼Œæ‚£è€…çš„æ‰‹æœ¯é€‚åº”ç—‡å’Œé£é™©éœ€è¦ç»¼åˆè€ƒè™‘ã€‚",
                TreatmentOption.CHEMOTHERAPY: "æ–°è¾…åŠ©åŒ–ç–—æˆ–è¾…åŠ©åŒ–ç–—çš„æ—¶æœºé€‰æ‹©å¯¹æ‰‹æœ¯æ•ˆæœå¾ˆé‡è¦ã€‚",
                TreatmentOption.RADIOTHERAPY: "æ”¾ç–—ä¸æ‰‹æœ¯çš„é…åˆæ—¶æœºéœ€è¦å¤šå­¦ç§‘å›¢é˜Ÿè®¨è®ºå†³å®šã€‚",
            },
            RoleType.RADIOLOGIST: {
                TreatmentOption.RADIOTHERAPY: "åŸºäºå½±åƒå­¦è¯„ä¼°ï¼Œæ”¾ç–—çš„é¶åŒºè®¾è®¡å’Œå‰‚é‡åˆ†å¸ƒéœ€è¦ç²¾ç¡®è§„åˆ’ã€‚",
                TreatmentOption.SURGERY: "å½±åƒå­¦æ£€æŸ¥ä¸ºæ‰‹æœ¯æ–¹æ¡ˆçš„åˆ¶å®šæä¾›äº†é‡è¦çš„è§£å‰–å­¦å‚è€ƒã€‚",
            },
            RoleType.NURSE: {
                TreatmentOption.CHEMOTHERAPY: "åŒ–ç–—æœŸé—´çš„æŠ¤ç†ç®¡ç†å’Œä¸è‰¯ååº”ç›‘æµ‹æ˜¯æ²»ç–—æˆåŠŸçš„å…³é”®ã€‚",
                TreatmentOption.SURGERY: "å›´æ‰‹æœ¯æœŸæŠ¤ç†å¯¹æ‚£è€…çš„åº·å¤å…·æœ‰é‡è¦æ„ä¹‰ã€‚",
                TreatmentOption.PALLIATIVE_CARE: "å§‘æ¯æŠ¤ç†èƒ½å¤Ÿæ˜¾è‘—æå‡æ‚£è€…çš„èˆ’é€‚åº¦å’Œç”Ÿæ´»è´¨é‡ã€‚",
            },
            RoleType.PSYCHOLOGIST: {
                TreatmentOption.CHEMOTHERAPY: "åŒ–ç–—æœŸé—´çš„å¿ƒç†æ”¯æŒæœ‰åŠ©äºæ‚£è€…æ›´å¥½åœ°é…åˆæ²»ç–—ã€‚",
                TreatmentOption.SURGERY: "æœ¯å‰å¿ƒç†å‡†å¤‡å’Œæœ¯åå¿ƒç†åº·å¤åŒæ ·é‡è¦ã€‚",
                TreatmentOption.PALLIATIVE_CARE: "å¿ƒç†å…³æ€€åœ¨å§‘æ¯æ²»ç–—ä¸­å‘æŒ¥ç€ä¸å¯æ›¿ä»£çš„ä½œç”¨ã€‚",
            },
        }

        # è·å–è§’è‰²ç‰¹å®šæ¨¡æ¿
        role_specific = role_templates.get(role, {})
        base_template = role_specific.get(
            treatment_option,
            f"ä½œä¸º{role.value}ï¼Œæˆ‘è®¤ä¸º{treatment_option.value}æ˜¯å€¼å¾—è€ƒè™‘çš„æ²»ç–—é€‰æ‹©ã€‚",
        )

        # æ·»åŠ æ‚£è€…ç‰¹å®šä¿¡æ¯
        patient_context = f"è€ƒè™‘åˆ°æ‚£è€…{patient_state.age}å²ï¼Œè¯Šæ–­ä¸º{patient_state.diagnosis}ï¼ˆ{patient_state.stage}æœŸï¼‰ï¼Œ"

        # å¦‚æœæœ‰è®¨è®ºä¸Šä¸‹æ–‡ï¼Œæ·»åŠ ç›¸å…³å›åº”
        context_response = ""
        if discussion_context and len(discussion_context.strip()) > 0:
            if "å®‰å…¨æ€§" in discussion_context or "é£é™©" in discussion_context:
                context_response = "å…³äºå®‰å…¨æ€§æ–¹é¢çš„è€ƒè™‘ï¼Œ"
            elif "æœ‰æ•ˆæ€§" in discussion_context or "æ•ˆæœ" in discussion_context:
                context_response = "ä»æ²»ç–—æ•ˆæœçš„è§’åº¦æ¥çœ‹ï¼Œ"
            elif "è´¹ç”¨" in discussion_context or "ç»æµ" in discussion_context:
                context_response = "åœ¨çš„ç»æµæ–¹é¢ï¼Œ"

        return f"{patient_context}{context_response}{base_template}"
